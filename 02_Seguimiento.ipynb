{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ciencia de Datos e Inteligencia Artificial para la industria del software**\n",
    "\n",
    "# *Curso MLOps*\n",
    "\n",
    "## **Edición 2023**\n",
    "\n",
    "# 2. Seguimiento de experimentos y gestión de modelos\n",
    "\n",
    "Las **hojas de cálculo** son una herramienta familiar y ampliamente utilizada en diferentes industrias para llevar adelante el **registro de eventos**. Muchas personas ya están familiarizadas con el software de hojas de cálculo como **Microsoft Excel o Google Sheets**, lo que facilita su adopción y uso para el **seguimiento de experimentos sin necesidad de aprendizaje o capacitación adicional.**\n",
    "\n",
    "Sin embargo, a medida que **aumenta la complejidad y escala de tus experimentos**, y tus **necesidades de seguimiento de experimentos evolucionan**, las plataformas de seguimiento de experimentos dedicadas pueden ofrecer **características más avanzadas y un mejor soporte para la reproducibilidad, la colaboración y la escalabilidad.**\n",
    "\n",
    "**¿Cúantas veces pensamos en abandonar algo por el nivel de desorganización que habiamos generado? (espero no ser el único)**\n",
    "\n",
    "## 2.1 Introducción al seguimiento de experimentos\n",
    "\n",
    "![MLOps_cycle](https://i0.wp.com/neptune.ai/wp-content/uploads/2022/11/MLOps_cycle.webp?resize=1020%2C574&ssl=1)\n",
    "\n",
    "* Seguimiento ≈ Experiment tracking -> \n",
    "\n",
    "El seguimiento de experimentos en el aprendizaje automático se refiere a la práctica de **registrar y organizar sistemáticamente información sobre experimentos de aprendizaje automático.** Implica capturar varios aspectos de un experimento, como **hiperparámetros, conjuntos de datos con los que se trabaja, arquitectura de cada modelo, métricas de evaluación y resultados**, además de cualquier comentario adicional que querramos hacer. Las plataformas o **herramientas de seguimiento** de experimentos a menudo se utilizan para **facilitar este proceso**. \n",
    "\n",
    "*Las herramientas de seguimiento estan totalmente infravaloradas, estas pueden ayudar notablemente a la organización y mejor ejecución de un proyecto.*\n",
    "\n",
    "El **propósito** del seguimiento de experimentos es permitir la **reproducibilidad, la colaboración y la optimización de flujos de trabajo de aprendizaje automático (organización)**. Al mantener un registro detallado de los experimentos, los investigadores y científicos de datos pueden **volver a visitar y reproducir fácilmente experimentos anteriores, comparar diferentes enfoques y tomar decisiones informadas sobre mejoras en el modelo.** El seguimiento de experimentos también ayuda a identificar patrones, comprender el impacto de varios factores en el rendimiento del modelo y compartir hallazgos con colegas.\n",
    "\n",
    "*Ya no nos dolera más la cabeza cuando nos pidan volver a revisar un antiguo proyecto.*\n",
    "\n",
    "## 2.2 Empezando con MLflow\n",
    "\n",
    "MLflow es una plataforma de código abierto para **gestionar el ciclo de vida del aprendizaje automático**. Proporciona un conjunto completo de **herramientas y API** para ayudar a los científicos de datos e ingenieros de aprendizaje automático a **realizar un seguimiento, gestionar e implementar** experimentos y modelos de aprendizaje automático. MLflow tiene como objetivo simplificar el proceso de **construir, compartir y reproducir** los proyectos de aprendizaje automático.\n",
    "\n",
    "Los **componentes principales de MLflow** son:\n",
    "\n",
    "* **Seguimiento**: MLflow Tracking permite a los usuarios **registrar y organizar experimentos**. Captura **parámetros, métricas y artefactos** (como modelos o visualizaciones) asociados con **cada ejecución**. El componente de seguimiento facilita la **comparación y la reproducibilidad** de experimentos, así como la **visualización** de resultados de experimentos.\n",
    "\n",
    "* **Proyectos**: Los Proyectos de MLflow proporcionan un **formato estándar** para **organizar y empaquetar código en un proyecto de aprendizaje automático**. Permite definir dependencias, especificar el punto de entrada para ejecutar el proyecto y reproducir y compartir fácilmente el proyecto con otros.\n",
    "\n",
    "* **Modelos**: MLflow Models proporciona una forma de **gestionar e implementar modelos** de aprendizaje automático de manera estandarizada. Admite varios formatos de modelo y permite la **implementación fácil** en diferentes entornos de ejecución, como implementación local o a través de APIs REST.\n",
    "\n",
    "* **Registro de modelos**: ***MLflow Model Registry* ofrece versionado de modelos, gestión de etapas y funciones de colaboración**. Permite a los equipos **gestionar y realizar un seguimiento del ciclo de vida de los modelos**, incluida la **transición de modelos** entre etapas de desarrollo, la aprobación y promoción de modelos y la habilitación de la colaboración entre miembros del equipo.\n",
    "\n",
    " El \"Model Registry\" de MLflow consta de **varios estados o etapas que los modelos pueden atravesar, lo que ayuda a organizar y administrar eficazmente los modelos en un entorno de producción**. A continuación, describiré las diferentes etapas en el \"Model Registry\" de MLflow:\n",
    "\n",
    " * **Staging** (En preparación): Esta es la **etapa inicial** de un modelo en el \"Model Registry\". Un modelo se encuentra en \"Staging\" cuando aún está **en desarrollo y no ha pasado por pruebas exhaustivas**. En esta etapa, los científicos de datos y los desarrolladores pueden **iterar sobre el modelo, probarlo y realizar experimentos sin afectar a los modelos en producción**. Los modelos en \"Staging\" pueden ser modificados y actualizados con frecuencia.\n",
    "\n",
    "* **Production** (Producción): Cuando un modelo ha **superado con éxito las pruebas en la etapa de \"Staging\"** y se considera apto para su **implementación en producción**, se mueve a la etapa de \"Production\". Los modelos en \"Production\" son los que **se utilizan en aplicaciones en tiempo real para realizar inferencias y tomar decisiones** basadas en el aprendizaje automático. Estos modelos deben ser estables y confiables, y se espera que tengan un rendimiento óptimo.\n",
    "\n",
    "* **Archived** (Archivado): Cuando un modelo **ya no es relevante o útil en producción**, se puede mover a la etapa de \"Archived\". Los modelos \"Archived\" se **retiran del servicio en producción y se almacenan en el \"Model Registry\" para su referencia futura o para cumplir con requisitos de auditoría y cumplimiento**.\n",
    "\n",
    "MLflow es compatible con **varios lenguajes de programación** (Python, R, Java, y REST APIs) y se integra con bibliotecas y marcos de aprendizaje automático populares como TensorFlow, PyTorch y scikit-learn. Se puede utilizar tanto en entornos locales como en entornos de cómputo distribuido como Apache Spark.\n",
    "\n",
    "**En resumen, MLflow simplifica el proceso de gestión y seguimiento de experimentos de aprendizaje automático, facilitando la colaboración, la reproducibilidad y la implementación de modelos de aprendizaje automático.**\n",
    "\n",
    "## 2.2.1 Instalar MLflow\n",
    "\n",
    "Ya estaba especificado en el requirements.txt. \n",
    "\n",
    "Chequearemos si se encuentra instalado correctamente:\n",
    "\n",
    "* *Abrir Windows PowerShell*\n",
    "\n",
    "```bash\n",
    "mlflow\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.2 La interfaz de usuario de MLFlow\n",
    "Para iniciar la interfaz de usuario de MLflow, introduzca lo siguiente desde la línea de comandos :\n",
    "\n",
    "**Ejectuar en la terminal!!**\n",
    "\n",
    "```bash\n",
    "mlflow ui --backend-store-uri sqlite:///mlflow.db\n",
    "```\n",
    "\n",
    "* **mlflow ui**: Esto **inicia la interfaz de usuario de MLflow**, que es una aplicación web que permite visualizar y administrar proyectos, experimentos, modelos y registros de modelos.\n",
    "\n",
    "* **--backend-store-uri sqlite:///mlflow.db**: Esto **especifica la ubicación y el tipo de almacenamiento que se utilizará para mantener los datos de MLflow**. En este caso, se está utilizando un archivo **SQLite llamado \"mlflow.db\"** como backend de almacenamiento. Esto significa que **la información sobre los experimentos, modelos, métricas y registros de modelos se almacenará en la base de datos SQLite en ese archivo**. Puedes cambiar la URI del almacén a otro sistema de almacenamiento compatible con MLflow, como una base de datos MySQL, PostgreSQL o un sistema de archivos.\n",
    "\n",
    "Una vez que ejecutas esta sentencia, la interfaz de usuario de MLflow se **iniciará y se abrirá en tu navegador web predeterminado**. Desde allí, podrás acceder y utilizar la interfaz de usuario para realizar un seguimiento de tus proyectos de aprendizaje automático, experimentos, modelos y registros de modelos, lo que te permitirá gestionar y supervisar eficazmente tus flujos de trabajo de aprendizaje automático."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importante**\n",
    "\n",
    "Asegúrate de iniciar la interfaz de usuario de MLflow desde el mismo directorio en el que se encuentran los scripts o el cuaderno Jupyter que está ejecutando los experimentos (el mismo directorio que contiene el directorio de MLflow y la base de datos que almacena los experimentos)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si no se inicia de forma automática, podemos ver la interfaz copiando y pegando **http://127.0.0.1:5000** en su navegador predeterminado. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten en cuenta que si recibes un **mensaje de error del tipo Conexión en uso: ('127.0.0.1', 5000)** significa que ya tienes algo ejecutándose en el puerto 5000, y necesitas eliminarlo.\n",
    "\n",
    "Ejecute el siguiente comando en el terminal:\n",
    "\n",
    "```bash\n",
    "ps -A | grep gunicorn\n",
    "```\n",
    "\n",
    "y luego busque el número id de proceso que es el 1er número después de ejecutar el comando. Luego finalizarlo, usando:\n",
    "\n",
    "```bash\n",
    "kill <process_id>\n",
    "```\n",
    "De momento no tenemos experimentos. Vamos a crear uno siguiendo el modelo de Regresión Lineal que construimos en el módulo anterior para predecir la duración de un viaje en taxi.\n",
    "\n",
    "```bash\n",
    "# check Python version\n",
    "python -V\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos las librerias necesarias que vamos a utilizar. \n",
    "\n",
    "import pandas as pd # working with tabular data\n",
    "import pickle # for machine learning models\n",
    "import seaborn as sns # visualization\n",
    "import matplotlib.pyplot as plt # visualization\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer # Machine Learning\n",
    "from sklearn.linear_model import LinearRegression # Machine Learning\n",
    "from sklearn.linear_model import Lasso # Regularization\n",
    "from sklearn.linear_model import Ridge # Regularization\n",
    "\n",
    "from sklearn.metrics import mean_squared_error # Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/marti/Desktop/CursoSadosky/MLops/mlruns/4', creation_time=1694711695214, experiment_id='4', last_update_time=1694711695214, lifecycle_stage='active', name='mlops_nyc_taxi_1', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importamos mlflow\n",
    "import mlflow\n",
    "\n",
    "# Establece la URI del seguimiento de MLflow en tu entorno. \n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "\n",
    "# Establece el experimento actual en MLflow, denominado \"mlops_nyc_taxi_1\". \n",
    "# Esto te permite organizar y agrupar todos los registros y métricas relacionadas con ese experimento en particular.\n",
    "mlflow.set_experiment(\"mlops_nyc_taxi_1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si volvemos a la interfaz de usuario de MLflow podemos ver que nuestro **experimento nyc_taxi_experiment se ha iniciado con éxito.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si recuerdas en el Módulo 1 el código era disperso, y se dificultaba su seguimiento. Vamos a replicarlo aquí para al menos obtener una **línea de base para la mejora utilizando MLflow.**\n",
    "\n",
    "* Esto es lo que haciamos antes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "        df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "        df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "    elif filename.endswith('.parquet'):\n",
    "        df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_dataframe('yellow_tripdata_2022-01.parquet')\n",
    "df_val = read_dataframe('yellow_tripdata_2022-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2421440, 2918187)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Feature engineering\"\n",
    "df_train['PU_DO'] = df_train['PULocationID'] + '_' + df_train['DOLocationID']\n",
    "df_val['PU_DO'] = df_val['PULocationID'] + '_' + df_val['DOLocationID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PU_DO'] #'PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.530572197116553"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_val)\n",
    "\n",
    "mean_squared_error(y_val, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully pickled.\n"
     ]
    }
   ],
   "source": [
    "# Guardabamos el modelo\n",
    "with open('./models/lin_reg.bin', 'wb') as f_out: # wb means write binary\n",
    "    try:\n",
    "        # Pickle both the dictionary vectorizer and the linear regression model\n",
    "        pickle.dump((dv, lr), f_out)\n",
    "        print(\"Model successfully pickled.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred while pickling the model:\", str(e))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora **aprovecharemos MLFlow** para incorporar algo de **estructura a nuestro flujo de trabajo**, haciéndolo más fácil de seguir, más fácil de iterar sobre diferentes modelos y parámetros, y más fácil de rastrear los cambios.\n",
    "\n",
    "Un fragmento de código se incluye a continuación para demostrar cómo podemos lograr esto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "\n",
    "    mlflow.set_tag(\"developer\", \"martin\")\n",
    "\n",
    "    mlflow.log_param(\"train-data-path\", \"./data/green_tripdata_2021-01.csv\")\n",
    "    mlflow.log_param(\"valid-data-path\", \"./data/green_tripdata_2021-02.csv\")\n",
    "\n",
    "    alpha = 0.1\n",
    "    mlflow.log_param(\"alpha\", alpha)\n",
    "    lr = Lasso(alpha)\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = lr.predict(X_val)\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    mlflow.log_artifact(local_path=\"models/lin_reg.bin\", artifact_path=\"models_pickle\") # where model saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **with mlflow.start_run()**: Se inicia una nueva ejecución de un experimento con MLflow utilizando el contexto with. Durante esta ejecución, se registrarán métricas, parámetros y artefactos que estén relacionados con esta ejecución específica.\n",
    "\n",
    "* **mlflow.set_tag(\"developer\", \"name\")*: Se agrega una etiqueta (tag) a la ejecución actual para proporcionar información adicional. En este caso, se está etiquetando la ejecución con el nombre del desarrollador, que es \"name\".\n",
    "\n",
    "* **mlflow.log_param(\"train-data-path\", \"./data/green_tripdata_2021-01.csv\") y mlflow.log_param(\"valid-data-path\", \"./data/green_tripdata_2021-02.csv\")**: Se registran parámetros relacionados con las rutas de los datos de entrenamiento y validación utilizados en el experimento. Esto permite mantener un registro de las ubicaciones de los conjuntos de datos utilizados en esta ejecución.\n",
    "\n",
    "* **alpha = 0.1 y mlflow.log_param(\"alpha\", alpha)**: Se define un **valor para el hiperparámetro alpha** y se registra como un **parámetro en MLflow**. Esto permite **rastrear** los valores de los hiperparámetros utilizados durante esta ejecución.\n",
    "\n",
    "* lr = Lasso(alpha) y lr.fit(X_train, y_train): Se **crea un modelo de regresión Lasso con el valor de alpha definido anteriormente y se ajusta a los datos de entrenamiento.**\n",
    "\n",
    "* y_pred = lr.predict(X_val): Se realiza una **predicción utilizando el modelo entrenado en el conjunto de validación.**\n",
    "\n",
    "* **rmse** = mean_squared_error(y_val, y_pred, squared=False): Se calcula la raíz del error cuadrático medio (RMSE) entre las predicciones y los valores reales del conjunto de validación.\n",
    "\n",
    "* **mlflow.log_metric(\"rmse\", rmse)**: Se **registra la métrica** RMSE en MLflow, lo que permite realizar un seguimiento de la métrica de rendimiento de esta ejecución.\n",
    "\n",
    "* **mlflow.log_artifact(local_path=\"models/lin_reg.bin\", artifact_path=\"models_pickle\")**: Se registra un **artefacto en MLflow**. En este caso, se está registrando un modelo guardado con el nombre \"lin_reg.bin\" en la ubicación local. El artefacto se guarda en el directorio \"models_pickle\" dentro de MLflow, lo que permite almacenar y recuperar modelos y otros archivos relacionados con esta ejecución.\n",
    "\n",
    "Si ahora volvemos a la interfaz de usuario de Mlflow podemos ver que el estado de la ejecución es **FINISHED** y se ha completado con éxito. Tenemos una nota de nuestro Tag, Parmaeters, Metrics y Artifacts como se especificó anteriormente en con mlflow.start_run():."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Seguimiento de experimentos con MLflow\n",
    "\n",
    "Veamos un modelo más complejo en acción en Mlflow, probaremos un XGBoost.\n",
    "\n",
    "### 2.3.1 XGBoost\n",
    "\n",
    "XGBoost, abreviatura de **\"Extreme Gradient Boosting\"**, es un algoritmo de aprendizaje automático popular conocido por su eficacia en tareas de modelado predictivo y análisis de datos. Pertenece a la familia de métodos de **gradient boosting**, que son técnicas de aprendizaje en conjunto que combinan múltiples modelos de predicción débiles, típicamente árboles de decisión, para crear un modelo de predicción sólido.\n",
    "\n",
    "XGBoost es especialmente conocido por su escalabilidad, eficiencia y precisión. Incorpora técnicas avanzadas como el aumento de gradiente, la regularización y el procesamiento paralelo para mejorar el rendimiento del modelo. Puede manejar una amplia gama de tipos de datos y a menudo se utiliza tanto para problemas de regresión como de clasificación.\n",
    "\n",
    "El algoritmo funciona construyendo de manera iterativa (**secuencial**) árboles de decisión para minimizar una función de pérdida especificada. Cada árbol subsiguiente se enfoca en **corregir los errores cometidos por los árboles anteriores**, lo que da como resultado un modelo de conjunto altamente preciso. Además, XGBoost permite objetivos de optimización personalizados y métricas de evaluación, lo que proporciona flexibilidad para abordar diversos dominios de problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos libreria del modelo\n",
    "import xgboost as xgb\n",
    "\n",
    "# Importamos libreria necesarias para la optimización de hyperparametros\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials # some methods to optimize hyperparameters\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enfoque del Estimador de Parzen Estructurado en Árbol (TPE) *Tree Parzen Estimator*\n",
    "\n",
    "El Enfoque del Estimador de Parzen Estructurado en Árbol (TPE) es un **algoritmo de optimización bayesiana** utilizado para la optimización de hiperparámetros en modelos de aprendizaje automático. Es una **alternativa popular a los métodos tradicionales de búsqueda en cuadrícula y búsqueda aleatoria**. TPE tiene como objetivo explorar eficientemente el espacio de hiperparámetros mediante la exploración y explotación iterativa de las regiones más prometedoras basadas en evaluaciones previas.\n",
    "\n",
    "TPE divide el espacio de búsqueda en **dos partes**: la **\"prior\"** y la **\"posterior\"**. La \"prior\" representa la **distribución de probabilidad de los hiperparámetros**, mientras que la \"posterior\" refleja la **distribución de probabilidad condicional de los hiperparámetros dados sus valores correspondientes de la función objetivo**. La priori y posteriori son funciones caracteristicas de lo que es el aprendizaje Bayesiano. \n",
    "\n",
    "El algoritmo **opera** en un proceso de **dos pasos**. Primero, construye un **modelo probabilístico para estimar la distribución posteriori** de los hiperparámetros utilizando un conjunto de puntos evaluados previamente. Este modelo se construye típicamente utilizando una estructura de árbol llamada \"ratio de densidad\" que captura las densidades relativas de hiperparámetros que funcionan mejor en comparación con los que funcionan peor.\n",
    "\n",
    "En el segundo paso, TPE **genera un nuevo conjunto de hiperparámetros candidatos muestreando de la distribución a posteriori estimada**. La selección de candidatos está **sesgada hacia las regiones con una mayor probabilidad de mejorar la función objetivo, aprovechando el conocimiento obtenido de las evaluaciones previas**.\n",
    "\n",
    "Al repetir iterativamente estos pasos, **TPE explora y refina el espacio de búsqueda de hiperparámetros, convergiendo gradualmente hacia la configuración óptima**. Se centra en explorar regiones prometedoras durante las primeras etapas de la optimización y explota esas regiones a medida que avanza la optimización.\n",
    "\n",
    "TPE ha ganado popularidad debido a su capacidad para explorar eficazmente espacios de hiperparámetros de alta dimensionalidad y complejos. Se ha aplicado con éxito en diversos campos, incluyendo el aprendizaje profundo, la selección de modelos de aprendizaje automático y el aprendizaje por refuerzo.\n",
    "\n",
    "Mas información sobre la forma en que optimizaremos este algoritmo -> [FMin](https://github.com/hyperopt/hyperopt/wiki/FMin)\n",
    "\n",
    "### hp\n",
    "\n",
    "En **Hyperopt**, los hiperparámetros se definen utilizando el módulo \"hp\" proporcionado por la biblioteca. Este módulo ofrece un conjunto de funciones para definir diferentes tipos de hiperparámetros, incluyendo hiperparámetros continuos, discretos y condicionales. Estas funciones permiten la creación de un **espacio de búsqueda sobre el cual el algoritmo de optimización puede explorar para encontrar los valores óptimos de los hiperparámetros.**\n",
    "\n",
    "### Trials\n",
    "\n",
    "Al pasar directamente un **objeto de \"Trials\"**, podemos inspeccionar todos los valores de retorno que se calcularon durante el experimento.\n",
    "\n",
    "* Facilita la exploración. \n",
    "\n",
    "Por ejemplo:\n",
    "\n",
    "- `trials.trials` - una lista de diccionarios que representan todo sobre la búsqueda\n",
    "- `trials.results` - una lista de diccionarios devueltos por 'objective' durante la búsqueda\n",
    "- `trials.losses()` - una lista de pérdidas (flotante para cada prueba 'ok')\n",
    "- `trials.statuses()` - una lista de cadenas de estado\n",
    "\n",
    "Este objeto de \"Trials\" se puede guardar, pasar a las rutinas de trazado incorporadas o analizar con su propio código personalizado.\n",
    "\n",
    "Ahora definamos nuestros conjuntos de datos de entrenamiento y validación y configuremos nuestra ejecución de MLflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formato especifico que pide la libreria xgboost\n",
    "train = xgb.DMatrix(X_train, label=y_train)\n",
    "valid = xgb.DMatrix(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function - set the parameters for this specific run\n",
    "def objective(params): \n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model\", \"xgboost\")\n",
    "        mlflow.log_params(params) \n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train, # model trained on training set\n",
    "            num_boost_round=3, # restricted due to time constraints - a value of 1000 iterations is common\n",
    "            evals=[(valid, 'validation')], # model evaluated on validation set\n",
    "            early_stopping_rounds=3 # if no improvements after 3 iterations, stop running # restricted, time constraints\n",
    "        )\n",
    "        y_pred = booster.predict(valid)\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    return {'loss': rmse, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la función **objective(params)** que se utiliza en una tarea de optimización de hiperparámetros:\n",
    "\n",
    "* **with mlflow.start_run()**: Se inicia una nueva ejecución de un experimento de MLflow. Cada llamada a esta función crea un nuevo registro para un experimento en MLflow. Todos los eventos, parámetros, métricas y artefactos registrados dentro de esta ejecución estarán asociados a esta ejecución particular.\n",
    "\n",
    "* **mlflow.set_tag(\"model\", \"xgboost\")**: Se agrega una etiqueta (tag) a la ejecución actual, indicando que se está utilizando el modelo XGBoost en este experimento.\n",
    "\n",
    "* **mlflow.log_params(params)**: Se registran los parámetros pasados a la función objective como argumento params en MLflow. Esto incluye los hiperparámetros que se utilizarán para entrenar el modelo XGBoost.\n",
    "\n",
    "* **booster = xgb.train(...)**: Se entrena un modelo XGBoost utilizando los hiperparámetros especificados en params. El modelo se entrena en el conjunto de datos de entrenamiento train con un número limitado de iteraciones **(num_boost_round=3)** debido a restricciones de tiempo. Además, se utiliza un conjunto de validación valid y se configura el **\"early stopping\"** para detener el entrenamiento si no se producen mejoras en la métrica de validación después de 3 iteraciones.\n",
    "\n",
    "* **y_pred** = booster.predict(valid): Se utilizan el modelo XGBoost entrenado para realizar predicciones en el conjunto de validación valid.\n",
    "\n",
    "* **rmse** = mean_squared_error(y_val, y_pred, squared=False): Se calcula la raíz del error cuadrático medio (RMSE) entre las predicciones y los valores reales del conjunto de validación. Esta métrica se utiliza para evaluar el rendimiento del modelo.\n",
    "\n",
    "* **mlflow.log_metric(\"rmse\", rmse)**: El valor del RMSE se registra como una métrica en MLflow, lo que permite realizar un seguimiento de las métricas de rendimiento del modelo para esta ejecución.\n",
    "\n",
    "Finalmente, se devuelve un diccionario con la pérdida (loss) y el estado (status) como resultado de la función de optimización. En este caso, la pérdida se establece en el valor del RMSE, y el estado se establece en \"STATUS_OK\" para indicar que la ejecución se completó con éxito.\n",
    "\n",
    "* Esta función objective(params) se utiliza para **entrenar un modelo XGBoost con diferentes configuraciones de hiperparámetros y evaluar su rendimiento utilizando RMSE**. Los resultados de cada ejecución se registran en MLflow para su seguimiento y comparación. Esto es común en la optimización de hiperparámetros, donde se busca encontrar los hiperparámetros óptimos para un modelo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Establecer el rango de búsqueda de optimización del hiperparámetro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Demora alrededor de 14 minutos, si no hicimos recreo podriamos hacer uno.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [14:57:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\objective\\regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:9.38268                          \n",
      "[1]\tvalidation-rmse:9.07785                          \n",
      "[2]\tvalidation-rmse:8.79249                          \n",
      " 33%|███▎      | 1/3 [06:04<12:09, 364.67s/trial, best loss: 8.792487368178712]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [15:03:59] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\objective\\regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:8.72719                                                    \n",
      "[1]\tvalidation-rmse:7.94317                                                    \n",
      "[2]\tvalidation-rmse:7.32237                                                    \n",
      " 67%|██████▋   | 2/3 [06:25<02:42, 162.20s/trial, best loss: 7.322371523338455]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [15:04:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\objective\\regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:6.37021                                                    \n",
      "[1]\tvalidation-rmse:5.43218                                                    \n",
      "[2]\tvalidation-rmse:5.16827                                                    \n",
      "100%|██████████| 3/3 [13:04<00:00, 261.49s/trial, best loss: 5.168265392658155]\n"
     ]
    }
   ],
   "source": [
    "# Definimos el espacio de busqueda\n",
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)), # tree depth 4 to 100. Returns float, so convert to integer\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, 0), # range exp(-3), exp(0) which is (0.049787, 1.0)\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -1), # range exp(-5), exp(-1) which is (0.006738, 0.367879)\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -6, -1), # range exp(-6), exp(-1) which is (0.002479, 0.367879)\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -1, 3), # range exp(-1), exp(3) which is (0.367879, 20.085537)\n",
    "    'objective': 'reg:linear',\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "\n",
    "best_result = fmin( # imported above\n",
    "    fn=objective,\n",
    "    space=search_space, # as defined above\n",
    "    algo=tpe.suggest, # tpe is the algorithm used for optimization\n",
    "    max_evals=3, #restricted, time constraints\n",
    "    trials=Trials()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acerca de como se creo la grilla:**\n",
    "\n",
    "*hp.quniform(label, low, high, q)*\n",
    "\n",
    "- Devuelve un valor como round(uniform(low, high) / q) * q\n",
    "- Adecuado para un valor discreto con respecto al cual el objetivo todavía es algo \"suave\", pero que debe estar acotado tanto por encima como por debajo.\n",
    "\n",
    "*hp.loguniform(label, low, high)*\n",
    "\n",
    "- Devuelve un valor dibujado de acuerdo con exp(uniform(low, high)) de modo que el logaritmo del valor de retorno esté distribuido de forma uniforme.\n",
    "- Cuando se optimiza, esta variable está limitada al intervalo [exp(low), exp(high)].\n",
    "\n",
    "Una guía detallada sobre cómo establecer el espacio de búsqueda se incluye en la documentación oficial de Hyperopt.\n",
    "\n",
    "### 2.3.3 Visualizaciones\n",
    "\n",
    "**Vista de tabla**\n",
    "\n",
    "La vista de tabla permite realizar una comparación básica. Puede especificar qué columnas mostrar. En mi caso, podemos ver que el modelo \"brawny-donkey-463\" devuelve el RMSE más bajo, 6.171, una mejora respecto a nuestra cifra de referencia de 9.71.\n",
    "\n",
    "**Vista de gráficos**\n",
    "\n",
    "La vista de gráficos ofrece una visualización ligeramente mejor, un gráfico de barras horizontal. Sin embargo, si queremos comprender completamente nuestros modelos, necesitamos una visualización más compleja que aborde las interrelaciones entre los diversos parámetros y su impacto en el RMSE.\n",
    "\n",
    "**Comparar**\n",
    "\n",
    "Puede filtrar los modelos que desea comparar utilizando \"tags.model=<nombre_del_modelo>\", seleccionarlos todos marcando las casillas y luego hacer clic en \"Comparar\".\n",
    "\n",
    "Explore:\n",
    "\n",
    "**Gráfico de coordenadas paralelas**\n",
    "\n",
    "**Gráfico de dispersión**\n",
    "\n",
    "**Gráfico de contorno**\n",
    "\n",
    "### 2.3.4 Selección del mejor modelo\n",
    "\n",
    "La forma más sencilla de clasificar los modelos es ordenar la columna de **Métricas** de la vista de tabla, sin embargo, no se trata únicamente de la métrica.\n",
    "\n",
    "La **velocidad** también es algo a considerar. En el ejemplo, aunque el modelo \"brawny-donkey-463\" devolvió el RMSE más bajo, el modelo \"youthful-hen-151\" fue el **más rápido**, con 2.1 segundos. El viejo adagio \"el tiempo es dinero\" es muy cierto en un entorno de producción, por lo que debemos tener en cuenta cuánto tiempo lleva entrenar nuestros modelos.\n",
    "\n",
    "La **complejidad del modelo es otro factor**. El modelo \"brawny-donkey-463\" es bastante **complejo** con \"max_depth=81\", mientras que el modelo \"youthful-hen-151\" es menos complejo con \"max_depth=11\". Cuanto mayor sea la complejidad, menor será la interpretabilidad. Necesitamos entender lo que nuestro modelo está haciendo \"bajo el capó\" antes de poder explicarlo.\n",
    "\n",
    "### 2.3.5 Entrenando el modelo seleccionado como el mejor\n",
    "\n",
    "Entonces, digamos que después de considerar cuidadosamente las métricas, el tiempo y la complejidad, decidimos optar por el modelo \"brawn-donkey-463\". Podemos tomar sus parámetros y copiarlos en un diccionario de parámetros:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': 0.6379934993414184,\n",
    "    'max_depth': 48,\n",
    "    'min_child_weight': 2.921791686074419,\n",
    "    'objective': 'reg:linear',\n",
    "    'reg_alpha': 0.044409064018651856,\n",
    "    'reg_lambda': 0.00981451912750773,\n",
    "    'seed': 42   \n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes aprovechar [Logging Automático](https://mlflow.org/docs/latest/tracking.html#automatic-logging).\n",
    "\n",
    "### 2.3.6 Logging Automático\n",
    "\n",
    "**El logging automático te permite registrar métricas, parámetros y modelos sin necesidad de declaraciones de registro explícitas.**\n",
    "\n",
    "* *Cuando se habilita el autologging, MLflow registra automáticamente métricas, parámetros y artefactos relacionados con el entrenamiento del modelo sin necesidad de que el usuario registre manualmente estos componentes.*\n",
    "\n",
    "Hay dos formas de usar el logging automático:\n",
    "\n",
    "1. Llama a mlflow.autolog() antes de tu código de entrenamiento. Esto habilitará el logging automático para cada biblioteca admitida que tengas instalada tan pronto como la importes.\n",
    "\n",
    "2. Usa llamadas específicas de autolog para cada biblioteca que utilices en tu código.\n",
    "\n",
    "Las siguientes bibliotecas admiten la autologización:\n",
    "\n",
    "* Scikit-learn\n",
    "* Keras\n",
    "* Gluon\n",
    "* XGBoost\n",
    "* LightGBM\n",
    "* Statsmodels\n",
    "* Spark\n",
    "* Fastai\n",
    "* Pytorch\n",
    "\n",
    "A continuación, podemos ejecutar el entrenamiento del modelo, en nuestro caso utilizando el prompt de la librería XGBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/07 15:26:36 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'c9572ee7e7eb452f8b093bf610f97bda', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current xgboost workflow\n",
      "2023/11/07 15:26:37 WARNING mlflow.xgboost: Failed to log dataset information to MLflow Tracking. Reason: Unable to allocate 186. GiB for an array with shape (2421440, 20667) and data type float32\n",
      "c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [15:26:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\objective\\regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:6.15483\n",
      "[1]\tvalidation-rmse:5.35559\n",
      "[2]\tvalidation-rmse:5.16269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/07 15:28:38 WARNING mlflow.xgboost: Failed to infer model signature: could not sample data to infer model signature: please ensure that autologging is enabled before constructing the dataset.\n",
      "2023/11/07 15:28:38 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [15:28:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\"\n"
     ]
    }
   ],
   "source": [
    "# Demora 2 min\n",
    "mlflow.xgboost.autolog()\n",
    "    \n",
    "booster = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=train, # model trained on training set\n",
    "    num_boost_round=3, # restricted due to time constraints - a value of 1000 iterations is common\n",
    "    evals=[(valid, 'validation')], # model evaluated on validation set\n",
    "    early_stopping_rounds=3 # if no improvements after 3 iterations, stop running # restricted, time constraints\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vamos a la interfaz de usuario podemos ver que se ha registrado un nuevo experimento con más información:\n",
    "\n",
    "* Si miramos las Métricas podemos visualizar la evolución del RMSE en las iteraciones sobre la base de datos de validación. \n",
    "\n",
    "* También tenemos los detalles del modelo por si queremos reproducirlo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Gestión de modelos\n",
    "\n",
    "![Ciclo de MLOps](https://i0.wp.com/neptune.ai/wp-content/uploads/2022/11/MLOps_cycle.webp?resize=1020%2C574&ssl=1)\n",
    "\n",
    "En la sección anterior, examinamos el Seguimiento de Experimentos, pero la gestión de modelos también abarca:\n",
    "\n",
    "- Model Versioning\n",
    "- Model Deployment\n",
    "- Scaling Hardware\n",
    "\n",
    "### 2.4.1 Model Versioning\n",
    "Podríamos usar un sistema de carpetas como una forma muy básica de gestionar las versiones de nuestros modelos, pero esto tiene varias limitaciones.\n",
    "\n",
    "![Sistema de carpetas](https://stephen137.github.io/posts/MLOps_Zoomcamp_Module_2/MLOps_Zoomcamp_Module_2_files/figure-html/ee079e29-1-folders.PNG)\n",
    "\n",
    "Veamos cómo podemos aprovechar MLflow para gestionar el control de versiones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.xgboost.autolog(disable=True) # MLflow will not store parameters automatically - these will have to be requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [15:38:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\objective\\regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:6.15483\n",
      "[1]\tvalidation-rmse:5.35559\n",
      "[2]\tvalidation-rmse:5.16269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [15:39:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\_distutils_hack\\__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "# Demora 2 min\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    train = xgb.DMatrix(X_train, label=y_train)\n",
    "    valid = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "    best_params = {\n",
    "        'learning_rate': 0.4434065752589766,\n",
    "        'max_depth': 81,\n",
    "        'min_child_weight': 10.423237853746643,\n",
    "        'objective': 'reg:linear',\n",
    "        'reg_alpha': 0.2630756846813668,\n",
    "        'reg_lambda': 0.1220536223877784,\n",
    "        'seed': 42    \n",
    "    }\n",
    "\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    booster = xgb.train(\n",
    "        params=params,\n",
    "        dtrain=train, # model trained on training set\n",
    "        num_boost_round=3, # restricted due to time constraints - a value of 1000 iterations is common\n",
    "        evals=[(valid, 'validation')], # model evaluated on validation set\n",
    "        early_stopping_rounds=3 # if no improvements after 3 iterations, stop running # restricted, time constraints\n",
    "        )\n",
    "\n",
    "    y_pred = booster.predict(valid)\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    with open(\"models/preprocessor.b\", \"wb\") as f_out: # save pre-processing as a model\n",
    "        pickle.dump(dv, f_out)\n",
    "        \n",
    "    mlflow.log_artifact(\"models/preprocessor.b\", artifact_path=\"preprocessor\") # we can isolate the pre-processing from raw data\n",
    "    mlflow.xgboost.log_model(booster, artifact_path=\"models_mlflow\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de ejecutar estas lineas podemos ver desde la interfaz de usuario que tanto el **modelo XGBoost** como el **preprocesador** se han guardado. Posteriormente estos elementos guardados como artefactos pueden cargarse para realizar el pre procesamiento de datos y generar predicciones con el modelo de XGBoost.\n",
    "\n",
    "**models_mlflow**\n",
    "\n",
    "### 2.4.2 Obtener predicciones\n",
    "\n",
    "MLflow proporciona fragmentos de código útiles para realizar predicciones en un DataFrame de Spark o pandas.\n",
    "\n",
    "Vamos a usar pandas y hacer una predicción. Primero, carguemos el modelo. Hay dos formas disponibles, `python_function` o, alternativamente, `xgboost`.\n",
    "\n",
    "`python_function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/07 15:43:21 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - mlflow (current: 2.7.1, required: mlflow==2.4)\n",
      " - numpy (current: 1.26.0, required: numpy==1.25.1)\n",
      " - pandas (current: 2.1.1, required: pandas==2.0.3)\n",
      " - psutil (current: 5.9.5, required: psutil==5.9.0)\n",
      " - scikit-learn (current: 1.3.1, required: scikit-learn==1.3.0)\n",
      " - scipy (current: 1.11.2, required: scipy==1.11.1)\n",
      " - typing-extensions (current: 4.8.0, required: typing-extensions==4.7.1)\n",
      " - xgboost (current: 2.0.0, required: xgboost==1.7.6)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n",
      "2023/11/07 15:43:21 WARNING mlflow.pyfunc: The version of Python that the model was saved in, `Python 3.10.12`, differs from the version of Python that is currently running, `Python 3.9.7`, and may be incompatible\n",
      "c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [15:43:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\objective\\regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "logged_model = 'file:///c:/Users/marti/Desktop/CursoSadosky/MLops/mlruns/4/feaddbda7d3a4138bcd6b4f8db1f6f44/artifacts/models_mlflow'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  artifact_path: models_mlflow\n",
       "  flavor: mlflow.xgboost\n",
       "  run_id: feaddbda7d3a4138bcd6b4f8db1f6f44"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [15:44:05] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\objective\\regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "xgboost_model = mlflow.xgboost.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xgboost.core.Booster at 0x2a89efc8250>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can make predictions with this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgboost_model.predict(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.847052 , 17.987246 , 24.64872  , 25.763891 , 29.417316 ,\n",
       "       12.618283 , 23.466017 ,  5.1277075, 15.760189 , 16.288137 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the first 10\n",
    "y_pred[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumiendo esta sección, hemos visto que es posible **tomar un modelo entrenado** utilizando una variedad de bibliotecas diferentes y registrar ese modelo en MLflow. Luego, puede acceder a ese modelo utilizando diferentes funciones ya sea con Python o propias de cualquier biblioteca. Luego, se vuelve muy fácil **realizar predicciones** y posteriormente **implementar el modelo**, por ejemplo, como una función de Python, en un contenedor Docker, en un cuaderno Jupyter o tal vez como un trabajo por lotes en Spark. Además, puede implementar en un clúster de Kubernetes o en diferentes entornos en la nube, como Amazon SageMaker o Microsoft Azure.\n",
    "\n",
    "![Formato del modelo](https://stephen137.github.io/posts/MLOps_Zoomcamp_Module_2/MLOps_Zoomcamp_Module_2_files/figure-html/dceee7a2-1-model_format.PNG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Registro de modelos\n",
    "### 2.5.1 Motivación\n",
    "Imagina que eres un ingeniero de aprendizaje automático o MLOps y recibes el siguiente correo electrónico de un científico de datos:\n",
    "\n",
    "![Correo electrónico](https://stephen137.github.io/posts/MLOps_Zoomcamp_Module_2/MLOps_Zoomcamp_Module_2_files/figure-html/165e93d0-1-model_registry.PNG)\n",
    "\n",
    "Existen varias preguntas sin respuesta que deben resolverse antes de que te sientas cómodo al implementar el modelo, como:\n",
    "\n",
    "- **¿Qué ha cambiado desde la versión anterior?**\n",
    "- **¿Es necesario actualizar los hiperparámetros?**\n",
    "- **¿Se necesita algún preprocesamiento?**\n",
    "- **¿Cuáles son las dependencias necesarias para ejecutar el modelo?**\n",
    "\n",
    "Con el fin de evitar confusiones en la implementación del modelo debido a correspondencia por correo electrónico larga o ambigüedad, podemos aprovechar el **Registro de Modelos de MLflow.**\n",
    "\n",
    "![Registro de modelos](https://stephen137.github.io/posts/MLOps_Zoomcamp_Module_2/MLOps_Zoomcamp_Module_2_files/figure-html/218f3014-1-register_model.PNG)\n",
    "\n",
    "Ten en cuenta que el registro de modelos no equivale a la implementación. **Es una \"sala de espera\" de modelos que se asignarán a etapas de puesta en escena, producción o archivo.** \n",
    "\n",
    "### 2.5.2 Registro de un modelo\n",
    "\n",
    "Digamos que estamos contentos con nuestra ejecución whimsical-shad-190, que fue un modelo XGBoost, y ahora queremos moverlo a la etapa de puesta en escena. Para hacerlo, haz clic en **Registrar modelo y dale un nombre al modelo**:\n",
    "\n",
    "**Registrar modelo con el nombre mlops_nyc_taxi**\n",
    "\n",
    "Cuando vamos a la **pestaña de Modelos**, ahora podemos ver nuestro modelo registrado.\n",
    "\n",
    "### 2.5.3 Transición de etapa\n",
    "Mencionamos anteriormente que existen tres etapas: *Puesta en Escena, Producción y Archivo*. Como se puede ver arriba, nuestro modelo está recién registrado y aún no ha sido trasladado. Podemos hacer esto haciendo **click primero en la versión que deseamos poner en escena**, lo que nos lleva a otra pantalla.\n",
    "\n",
    "Haz click en **Stage** -> Transición a -> Puesta en Escena y si regresamos a nuestra pestaña de modelos, podemos ver que ahora se muestra en la columna de Puesta en Escena.\n",
    "\n",
    "### 2.5.4 Interacción con el servidor de seguimiento de MLflow\n",
    "El **módulo mlflow.client** proporciona una **interfaz** CRUD (acrónimo de Create, Read, Update, Delete) de Python para Experimentos, Ejecuciones, Versiones de Modelos y Modelos Registrados de MLflow, esta permite interactuar de forma directa con los componentes de MLflow desde código Python. Esta es una API de **bajo nivel** que se traduce directamente en llamadas a la API REST de MLflow.\n",
    "\n",
    "Esencialmente, esto **nos permite interactuar con la interfaz de usuario de MLflow y acceder a la misma información utilizando Python:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el modulo necesario\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_TRACKING_URI = \"sqlite:///mlflow.db\"\n",
    "\n",
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **MLFLOW_TRACKING_URI = \"sqlite:///mlflow.db\"**: En esta línea, se está configurando la dirección URI de seguimiento de MLflow. La dirección URI especifica dónde se almacenarán los datos y registros relacionados con los experimentos, ejecuciones de modelos y otros aspectos del seguimiento de MLflow. En este caso, se está configurando para utilizar una base de datos SQLite llamada **\"mlflow.db\"** como sistema de almacenamiento. Esto significa que todos los datos se almacenarán localmente en un archivo de base de datos SQLite.\n",
    "\n",
    "* **client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)**: Luego, se inicializa un cliente de MLflow llamado client utilizando la dirección URI de seguimiento configurada anteriormente. El cliente se utiliza para interactuar con el sistema de seguimiento de MLflow, lo que incluye la recuperación de información sobre experimentos, ejecuciones, modelos registrados y más. Al especificar la dirección URI al crear el cliente, le estás indicando al cliente dónde buscar y almacenar datos.\n",
    "\n",
    "Imaginemos que intentamos comprender, para un experimento determinado, cuáles son los mejores modelos o ejecuciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.entities import ViewType\n",
    "\n",
    "runs = client.search_runs(\n",
    "    experiment_ids='4', # mlops_nyc_taxi\n",
    "    filter_string=\"metrics.rmse < 10\", # grab only the runs with an RMSE below 10\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    max_results=5,\n",
    "    order_by=[\"metrics.rmse ASC\"] # Ascending\n",
    ")\n",
    "\n",
    "# Buscar id del experiment que inicializamos y colocarlo en experiment_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **from mlflow.entities import ViewType**: Esta línea importa la enumeración ViewType desde el módulo mlflow.entities. La enumeración ViewType se utiliza para especificar el tipo de vista de las ejecuciones que se deben buscar. En este caso, se está importando para usar el tipo de vista \"ACTIVE_ONLY\", lo que significa que se buscarán solo ejecuciones activas.\n",
    "\n",
    "* **runs = client.search_runs(...)**: Se utiliza el cliente de MLflow (client) para realizar una búsqueda de ejecuciones de experimentos. Los argumentos que se proporcionan en esta búsqueda son los siguientes:\n",
    "\n",
    "* **experiment_ids='4'**: Se especifica el ID del experimento en el que se desea buscar ejecuciones. En este caso, el experimento tiene un ID igual a 4, que corresponde al experimento llamado \"mlops_nyc_taxi\".\n",
    "\n",
    "* **filter_string=\"metrics.rmse < 10\"**: Se define un filtro de búsqueda para recuperar solo las ejecuciones que cumplan con ciertos criterios. En este caso, se están seleccionando ejecuciones cuya métrica \"rmse\" sea menor que 10. Esto permite filtrar las ejecuciones en función de su rendimiento, eligiendo aquellas con un error cuadrático medio (RMSE) por debajo de 10.\n",
    "\n",
    "* **run_view_type=ViewType.ACTIVE_ONLY**: Se especifica el tipo de vista de las ejecuciones que se deben buscar. En este caso, se está buscando solo ejecuciones activas, lo que significa que se excluyen aquellas que han sido finalizadas o cerradas.\n",
    "\n",
    "* **max_results=5**: Se limita la cantidad máxima de resultados que se recuperarán a 5 ejecuciones. Esto garantiza que solo se obtengan un máximo de 5 resultados, incluso si hay más ejecuciones que coinciden con los criterios de búsqueda.\n",
    "\n",
    "* **order_by=[\"metrics.rmse ASC\"]**: Se indica cómo se deben ordenar los resultados. En este caso, se ordenan en orden ascendente (ASC) según la métrica \"rmse\". Esto significa que las ejecuciones con el RMSE más bajo aparecerán primero en la lista de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id: 37a5bb0dc7e84499ac8a8eeb6ecea675, rmse: 5.1024\n",
      "run id: cf1de24cf10d46749b3dcfd5e0a3b1b1, rmse: 5.1352\n",
      "run id: 2d636098f6fd4e7ebde3d4416e02ca07, rmse: 5.1627\n",
      "run id: c77ad7dc58194ebdb99a736642d2ff2a, rmse: 5.1627\n",
      "run id: f5caede9e9b6414ca8801a629c8e2811, rmse: 5.1627\n"
     ]
    }
   ],
   "source": [
    "for run in runs:\n",
    "    print(f\"run id: {run.info.run_id}, rmse: {run.data.metrics['rmse']:.4f}\") # round to 4 d.p"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.5 Interactuando con el Registro de Modelos\n",
    "En esta sección, utilizaremos la instancia de MlflowClient para:\n",
    "\n",
    "* Registrar una nueva versión para el experimento mlops_nyc_taxi\n",
    "* Recuperar las últimas versiones del modelo nyc_taxi_xgb y verificar que se haya creado una nueva versión\n",
    "* Transicionar la nueva versión 2 a \"Puesta en Escena\"\n",
    "* Agregar anotaciones\n",
    "\n",
    "Registrar una nueva versión para el experimento mlops_nyc_taxi\n",
    "\n",
    "**Analizar pestaña Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'martin2.0' already exists. Creating a new version of this model...\n",
      "2023/11/07 16:12:30 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: martin2.0, version 2\n",
      "Created version '2' of model 'martin2.0'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1699384350731, current_stage='None', description=None, last_updated_timestamp=1699384350731, name='martin2.0', run_id='2d636098f6fd4e7ebde3d4416e02ca07', run_link=None, source='file:///c:/Users/marti/Desktop/CursoSadosky/MLops/mlruns/4/2d636098f6fd4e7ebde3d4416e02ca07/artifacts/model', status='READY', status_message=None, tags={}, user_id=None, version=2>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# register the top performing model(run) from the mlops_nyc_taxi experiment\n",
    "run_id = \"2d636098f6fd4e7ebde3d4416e02ca07\" \n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "mlflow.register_model(model_uri=model_uri, name=\"martin2.0\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que ahora tenemos la versión 2 de nuestro modelo.\n",
    "\n",
    "Recuperar las últimas versiones del modelo nyc_taxi_xgb y comprobar que se ha creado una nueva versión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: 1, stage: Staging\n",
      "version: 2, stage: None\n"
     ]
    }
   ],
   "source": [
    "# Poner bien el model name\n",
    "model_name = \"martin2.0\"\n",
    "latest_versions = client.get_latest_versions(name=model_name)\n",
    "\n",
    "for version in latest_versions:\n",
    "    print(f\"version: {version.version}, stage: {version.current_stage}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transición de la nueva versión 2 a \"Staging\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1699384350731, current_stage='Staging', description=None, last_updated_timestamp=1699384516565, name='martin2.0', run_id='2d636098f6fd4e7ebde3d4416e02ca07', run_link=None, source='file:///c:/Users/marti/Desktop/CursoSadosky/MLops/mlruns/4/2d636098f6fd4e7ebde3d4416e02ca07/artifacts/model', status='READY', status_message=None, tags={}, user_id=None, version=2>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_version = 2\n",
    "new_stage = \"Staging\"\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    "    stage=new_stage,\n",
    "    archive_existing_versions=False # so version 1 will remain in Staging\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que esto se ha realizado exitosamente, la vesión 2 ahora esta en stagging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1699384350731, current_stage='Staging', description='The model version 2 was transitioned to Staging on 2023-11-07', last_updated_timestamp=1699384543144, name='martin2.0', run_id='2d636098f6fd4e7ebde3d4416e02ca07', run_link=None, source='file:///c:/Users/marti/Desktop/CursoSadosky/MLops/mlruns/4/2d636098f6fd4e7ebde3d4416e02ca07/artifacts/model', status='READY', status_message=None, tags={}, user_id=None, version=2>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "date = datetime.today().date()\n",
    "client.update_model_version(\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    "    description=f\"The model version {model_version} was transitioned to {new_stage} on {date}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadamos la Versión 1 a **Producción** para utilizarla en la ilustración que sigue en la siguiente sección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1699383003175, current_stage='Production', description='The model version 1 was transitioned to Production on 2023-11-07', last_updated_timestamp=1699384546571, name='martin2.0', run_id='2d636098f6fd4e7ebde3d4416e02ca07', run_link='', source='file:///c:/Users/marti/Desktop/CursoSadosky/MLops/mlruns/4/2d636098f6fd4e7ebde3d4416e02ca07/artifacts/models_mlflow', status='READY', status_message=None, tags={}, user_id=None, version=1>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_version = 1\n",
    "new_stage = \"Production\"\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    "    stage=new_stage,\n",
    "    archive_existing_versions=False # \n",
    ")\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "date = datetime.today().date()\n",
    "client.update_model_version(\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    "    description=f\"The model version {model_version} was transitioned to {new_stage} on {date}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.6 Comparing versions and selecting the new “Production” model\n",
    "En esta última sección, recuperaremos los **modelos registrados en el registro de modelos** y **compararemos su rendimiento en un conjunto de prueba no visto**. La idea es simular el escenario en el que un **implementador tiene que interactuar con el registro de modelos** para decidir si actualizar o no la versión del modelo que está en producción.\n",
    "\n",
    "Estos son los pasos:\n",
    "\n",
    "* Cargar el conjunto de datos de prueba, que corresponde a los datos de los taxis amarillos de Nueva York del mes de marzo de 2022.\n",
    "* Descargar el DictVectorizer que se ajustó utilizando los datos de entrenamiento y se guardó en MLflow como un artefacto, y cargarlo con pickle.\n",
    "* Procesar el conjunto de pruebas utilizando el DictVectorizer.\n",
    "* Realizar predicciones en el conjunto de pruebas utilizando la versión del modelo que actualmente está en la etapa de \"Producción\".\n",
    "* Basándonos en los resultados, actualizar la versión del modelo en \"Producción\" en consecuencia.\n",
    "\n",
    "**Registro de modelos**\n",
    "\n",
    "El registro de modelos en realidad no implementa el modelo en producción cuando se transfiere un modelo a la etapa de \"Producción\", simplemente asigna una etiqueta a esa versión del modelo. Debe complementar el registro con algún código de CI/CD que realice la implementación real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download March 2022 yellow taxi data as `test` dataset\n",
    "# we used Feb 2022 for validation (which is sometimes also effectively the 'test' set)\n",
    "\n",
    "# !wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our functions\n",
    "\n",
    "def read_dataframe(filename):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "        df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "        df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "    elif filename.endswith('.parquet'):\n",
    "        df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocess(df, dv):\n",
    "    df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n",
    "    categorical = ['PU_DO']\n",
    "    numerical = ['trip_distance']\n",
    "    train_dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "    return dv.transform(train_dicts) # not fitting the pre-processor again\n",
    "\n",
    "\n",
    "def test_model(name, stage, X_test, y_test):\n",
    "    model = mlflow.pyfunc.load_model(f\"models:/{name}/{stage}\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    return {\"rmse\": mean_squared_error(y_test, y_pred, squared=False)}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargue el conjunto de datos de prueba, que corresponde a los datos de NYC Yellow Taxi del mes de marzo de 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_dataframe(\"yellow_tripdata_2022-03.parquet\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descargue el DictVectorizer que fue ajustado utilizando los datos de entrenamiento y guardado en MLflow como un artefacto, y cárguelo con pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|██████████| 1/1 [00:00<00:00, 76.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\marti\\\\Desktop\\\\CursoSadosky\\\\MLops\\\\preprocessor'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.download_artifacts(run_id=run_id, path='preprocessor', dst_path='.') # downloaded locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"preprocessor/preprocessor.b\", \"rb\") as f_in:\n",
    "    dv = pickle.load(f_in)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesar el conjunto de pruebas con el DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = preprocess(df, dv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar predicciones sobre el conjunto de pruebas - modelo en Producción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"duration\"\n",
    "y_test = df[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/07 16:18:51 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - mlflow (current: 2.7.1, required: mlflow==2.4)\n",
      " - numpy (current: 1.26.0, required: numpy==1.25.1)\n",
      " - pandas (current: 2.1.1, required: pandas==2.0.3)\n",
      " - psutil (current: 5.9.5, required: psutil==5.9.0)\n",
      " - scikit-learn (current: 1.3.1, required: scikit-learn==1.3.0)\n",
      " - scipy (current: 1.11.2, required: scipy==1.11.1)\n",
      " - typing-extensions (current: 4.8.0, required: typing-extensions==4.7.1)\n",
      " - xgboost (current: 2.0.0, required: xgboost==1.7.6)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n",
      "2023/11/07 16:18:51 WARNING mlflow.pyfunc: The version of Python that the model was saved in, `Python 3.10.12`, differs from the version of Python that is currently running, `Python 3.9.7`, and may be incompatible\n",
      "c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [16:18:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\objective\\regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# From the experiments, model script\n",
    "logged_model = 'runs:/feaddbda7d3a4138bcd6b4f8db1f6f44/models_mlflow'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on a Pandas DataFrame.\n",
    "import pandas as pd\n",
    "y_predict=loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.561789023449282"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_predict, squared=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así pues, el RMSE es sólo ligeramente superior (6,505) y el rendimiento es ligeramente peor cuando se prueba con los datos no vistos de marzo de 2022 que con la métrica del conjunto de validación (6,171)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 MLflow en la práctica\n",
    "**Consideremos tres escenarios:**\n",
    "\n",
    "1. Un **único científico de datos participando en una competencia de ML**.\n",
    "2. Un **equipo interdisciplinario con un científico de datos trabajando en un modelo de ML**.\n",
    "3. **Múltiples científicos de datos trabajando en múltiples modelos de ML**.\n",
    "\n",
    "### 2.6.1 Un único científico de datos participando en una competencia de ML\n",
    "En este caso de uso, tener un servidor de seguimiento remoto sería excesivo. No es necesario compartir información con otros y usar un registro de modelos sería inútil, porque no hay posibilidad de implementación del modelo en producción.\n",
    "\n",
    "**Configuración de MLflow:**\n",
    "\n",
    "* Servidor de seguimiento: no\n",
    "* Almacenamiento de backend: sistema de archivos local\n",
    "* Almacenamiento de artefactos: sistema de archivos local\n",
    "\n",
    "Los experimentos se pueden explorar localmente iniciando la interfaz de usuario de MLflow.\n",
    "\n",
    "### 2.6.2 Un equipo interdisciplinario con un científico de datos trabajando en un modelo de ML\n",
    "La información deberá compartirse con el equipo interdisciplinario, pero no necesariamente hay necesidad de ejecutar un servidor de seguimiento de forma remota; localmente puede ser suficiente. Usar el registro de modelos podría ser una buena idea para gestionar el ciclo de vida de los modelos, pero no está claro si necesitamos ejecutarlo de forma remota o en el host local.\n",
    "\n",
    "**Configuración de MLflow:**\n",
    "\n",
    "* Servidor de seguimiento: sí, servidor local\n",
    "* Almacenamiento de backend: base de datos sqlite\n",
    "* Almacenamiento de artefactos: sistema de archivos local\n",
    "\n",
    "Los experimentos se pueden explorar localmente accediendo al servidor de seguimiento local.\n",
    "\n",
    "Para ejecutar este ejemplo, debe iniciar el servidor de MLflow localmente ejecutando el siguiente comando en su terminal:\n",
    "\n",
    "!mlflow server --backend-store-uri sqlite:///backend.db\n",
    "\n",
    "### 2.6.3 Múltiples científicos de datos trabajando en múltiples modelos de ML\n",
    "Compartir información es muy importante en este escenario. Existe colaboración entre científicos para construir modelos y, por lo tanto, necesitan un servidor de seguimiento remoto y deben hacer uso del registro de modelos.\n",
    "\n",
    "**Configuración de MLflow:**\n",
    "\n",
    "* Servidor de seguimiento: sí, servidor remoto (EC2)\n",
    "* Almacenamiento de backend: base de datos postgresql\n",
    "* Almacenamiento de artefactos: cubo de s3\n",
    "\n",
    "Los experimentos se pueden explorar accediendo al servidor remoto.\n",
    "\n",
    "El ejemplo utiliza AWS para alojar un servidor remoto. Para ejecutar el ejemplo, necesitará una cuenta de AWS. Siga los pasos descritos a continuación para crear una nueva cuenta de AWS y lanzar el servidor de seguimiento.\n",
    "\n",
    "[Más información sobre MLflow](https://mlflow.org/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
