{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ciencia de Datos e Inteligencia Artificial para la industria del software**\n",
    "\n",
    "# *Curso MLOps*\n",
    "\n",
    "## **Edición 2023**\n",
    "\n",
    "# 2. Seguimiento de experimentos y gestión de modelos\n",
    "\n",
    "Las hojas de cálculo son una herramienta familiar y ampliamente utilizada en diferentes industrias. Muchas personas ya están familiarizadas con el software de hojas de cálculo como Microsoft Excel o Google Sheets, lo que facilita su adopción y uso para el seguimiento de experimentos sin necesidad de aprendizaje o capacitación adicional.\n",
    "\n",
    "Sin embargo, a medida que aumenta la complejidad y escala de tus experimentos, y tus necesidades de seguimiento de experimentos evolucionan, las plataformas de seguimiento de experimentos dedicadas pueden ofrecer características más avanzadas y un mejor soporte para la reproducibilidad, la colaboración y la escalabilidad.\n",
    "\n",
    "## 2.1 Introducción al seguimiento de experimentos\n",
    "\n",
    "![MLOps_cycle](https://i0.wp.com/neptune.ai/wp-content/uploads/2022/11/MLOps_cycle.webp?resize=1020%2C574&ssl=1)\n",
    "\n",
    "El seguimiento de experimentos en el aprendizaje automático se refiere a la práctica de registrar y organizar sistemáticamente información sobre experimentos de aprendizaje automático. Implica capturar varios aspectos de un experimento, como **hiperparámetros, conjuntos de datos, arquitectura del modelo, métricas de evaluación y resultados**. Las plataformas o herramientas de seguimiento de experimentos a menudo se utilizan para facilitar este proceso.\n",
    "\n",
    "El propósito del seguimiento de experimentos es permitir la **reproducibilidad, la colaboración y la optimización de flujos de trabajo de aprendizaje automático (organización)**. Al mantener un registro detallado de los experimentos, los investigadores y científicos de datos pueden volver a visitar y reproducir fácilmente experimentos anteriores, comparar diferentes enfoques y tomar decisiones informadas sobre mejoras en el modelo. El seguimiento de experimentos también ayuda a identificar patrones, comprender el impacto de varios factores en el rendimiento del modelo y compartir hallazgos con colegas.\n",
    "\n",
    "## 2.2 Empezando con MLflow\n",
    "\n",
    "MLflow es una plataforma de código abierto para **gestionar el ciclo de vida del aprendizaje automático**. Proporciona un conjunto completo de **herramientas y API** para ayudar a los científicos de datos e ingenieros de aprendizaje automático a realizar un seguimiento, gestionar e implementar experimentos y modelos de aprendizaje automático. MLflow tiene como objetivo simplificar el proceso de construcción, compartición y reproducción de proyectos de aprendizaje automático.\n",
    "\n",
    "Los componentes principales de MLflow son:\n",
    "\n",
    "* **Seguimiento**: MLflow Tracking permite a los usuarios **registrar y organizar experimentos**. Captura parámetros, métricas y artefactos (como modelos o visualizaciones) asociados con cada ejecución. El componente de seguimiento facilita la comparación y la reproducibilidad de experimentos, así como la visualización de resultados de experimentos.\n",
    "\n",
    "* **Proyectos**: Los Proyectos de MLflow proporcionan un formato estándar para **organizar y empaquetar código en un proyecto de aprendizaje automático**. Permite definir dependencias, especificar el punto de entrada para ejecutar el proyecto y reproducir y compartir fácilmente el proyecto con otros.\n",
    "\n",
    "* **Modelos**: MLflow Models proporciona una forma de **gestionar e implementar modelos** de aprendizaje automático de manera estandarizada. Admite varios formatos de modelo y permite la implementación fácil en diferentes entornos de ejecución, como implementación local o a través de APIs REST.\n",
    "\n",
    "* **Registro de modelos**: **MLflow Model Registry ofrece versionado de modelos, gestión de etapas y funciones de colaboración**. Permite a los equipos gestionar y realizar un seguimiento del ciclo de vida de los modelos, incluida la transición de modelos entre etapas de desarrollo, la aprobación y promoción de modelos y la habilitación de la colaboración entre miembros del equipo.\n",
    "\n",
    "MLflow es compatible con varios lenguajes de programación e se integra con bibliotecas y marcos de aprendizaje automático populares como TensorFlow, PyTorch y scikit-learn. Se puede utilizar tanto en entornos locales como en entornos de cómputo distribuido como Apache Spark.\n",
    "\n",
    "En resumen, MLflow simplifica el proceso de gestión y seguimiento de experimentos de aprendizaje automático, facilitando la colaboración, la reproducibilidad y la implementación de modelos de aprendizaje automático.\n",
    "\n",
    "## 2.2.1 Instalar MLflow\n",
    "\n",
    "Ya estaba especificado en el requirements.txt. \n",
    "\n",
    "Chequearemos si se encuentra instalado correctamente:\n",
    "\n",
    "```bash\n",
    "mlflow\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.2 La interfaz de usuario de MLFlow\n",
    "Para iniciar la interfaz de usuario de MLflow, introduzca lo siguiente desde la línea de comandos :\n",
    "\n",
    "**Ejectuar en la terminal!!**\n",
    "\n",
    "```bash\n",
    "mlflow ui --backend-store-uri sqlite:///mlflow.db\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importante**\n",
    "\n",
    "Asegúrate de iniciar la interfaz de usuario de MLflow desde el mismo directorio en el que se encuentran los scripts o el cuaderno Jupyter que está ejecutando los experimentos (el mismo directorio que contiene el directorio de MLflow y la base de datos que almacena los experimentos)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funcionó sin problemas.\n",
    "\n",
    "Y podemos ver copiando el enlace resaltado http://127.0.0.1:5000 en su navegador:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten en cuenta que si recibes un mensaje de error del tipo Conexión en uso: ('127.0.0.1', 5000) significa que ya tienes algo ejecutándose en el puerto 5000, y necesitas eliminarlo.\n",
    "\n",
    "Ejecute el siguiente comando en el terminal:\n",
    "\n",
    "```bash\n",
    "ps -A | grep gunicorn\n",
    "```\n",
    "\n",
    "y luego busque el número id de proceso que es el 1er número después de ejecutar el comando. Luego finalizarlo, usando:\n",
    "\n",
    "```bash\n",
    "kill <process_id>\n",
    "```\n",
    "De momento no tenemos experimentos. Vamos a crear uno siguiendo el modelo de Regresión Lineal que construimos en el módulo anterior para predecir la duración de un viaje en taxi.\n",
    "\n",
    "```bash\n",
    "# check Python version\n",
    "python -V\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # working with tabular data\n",
    "import pickle # for machine learning models\n",
    "import seaborn as sns # visualization\n",
    "import matplotlib.pyplot as plt # visualization\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer # Machine Learning\n",
    "from sklearn.linear_model import LinearRegression # Machine Learning\n",
    "from sklearn.linear_model import Lasso # Regularization\n",
    "from sklearn.linear_model import Ridge # Regularization\n",
    "\n",
    "from sklearn.metrics import mean_squared_error # Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/marti/Desktop/CursoSadosky/MLops/mlruns/4', creation_time=1694711695214, experiment_id='4', last_update_time=1694711695214, lifecycle_stage='active', name='mlops_nyc_taxi_1', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# to hook up with MLFlow UI\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"mlops_nyc_taxi_1\") # choose a name for your experiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si volvemos a la interfaz de usuario de MLflow podemos ver que nuestro experimento nyc_taxi_experiment se ha iniciado con éxito."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si recuerdas en el Módulo 1 el código era disperso, y a veces difícil de seguir. Vamos a replicarlo aquí para al menos obtener una línea de base para la mejora utilizando MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "        df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "        df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "    elif filename.endswith('.parquet'):\n",
    "        df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_dataframe('yellow_tripdata_2022-01.parquet')\n",
    "df_val = read_dataframe('yellow_tripdata_2022-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2421440, 2918187)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['PU_DO'] = df_train['PULocationID'] + '_' + df_train['DOLocationID']\n",
    "df_val['PU_DO'] = df_val['PULocationID'] + '_' + df_val['DOLocationID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PU_DO'] #'PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.530572197116553"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_val)\n",
    "\n",
    "mean_squared_error(y_val, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully pickled.\n"
     ]
    }
   ],
   "source": [
    "with open('./models/lin_reg.bin', 'wb') as f_out: # wb means write binary\n",
    "    try:\n",
    "        # Pickle both the dictionary vectorizer and the linear regression model\n",
    "        pickle.dump((dv, lr), f_out)\n",
    "        print(\"Model successfully pickled.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred while pickling the model:\", str(e))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aprovechemos **MLFlow** para incorporar algo de estructura a nuestro flujo, haciéndolo más fácil de seguir, más fácil de iterar sobre diferentes modelos y parámetros, y más fácil de rastrear los cambios.\n",
    "\n",
    "Un fragmento de código se incluye a continuación para demostrar cómo podemos lograr esto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "\n",
    "    mlflow.set_tag(\"developer\", \"martin\")\n",
    "\n",
    "    mlflow.log_param(\"train-data-path\", \"./data/green_tripdata_2021-01.csv\")\n",
    "    mlflow.log_param(\"valid-data-path\", \"./data/green_tripdata_2021-02.csv\")\n",
    "\n",
    "    alpha = 0.1\n",
    "    mlflow.log_param(\"alpha\", alpha)\n",
    "    lr = Lasso(alpha)\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = lr.predict(X_val)\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    mlflow.log_artifact(local_path=\"models/lin_reg.bin\", artifact_path=\"models_pickle\") # where model saved"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mlflow.log_artifact() registra un archivo local o directorio como un artefacto, opcionalmente tomando un artifact_path para colocarlo dentro del URI del artefacto de ejecución. Los artefactos de ejecución pueden organizarse en directorios, por lo que puedes colocar el artefacto en un directorio de esta forma.\n",
    "\n",
    "Si ahora volvemos a la interfaz de usuario de Mlflow podemos ver que el estado de la ejecución es FINISHED y se ha completado con éxito. Tenemos una nota de nuestro Tag, Parmaeters, Metrics y Artifacts como se especificó anteriormente en con mlflow.start_run():."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Seguimiento de experimentos con MLflow\n",
    "\n",
    "### 2.3.1 XGBoost\n",
    "\n",
    "Para demostrar más completamente las capacidades de MLflow, veamos un modelo más complejo que utiliza XGBoost.\n",
    "\n",
    "XGBoost, abreviatura de \"Extreme Gradient Boosting\", es un algoritmo de aprendizaje automático popular conocido por su eficacia en tareas de modelado predictivo y análisis de datos. Pertenece a la familia de métodos de **gradient boosting**, que son técnicas de aprendizaje en conjunto que combinan múltiples modelos de predicción débiles, típicamente árboles de decisión, para crear un modelo de predicción sólido.\n",
    "\n",
    "XGBoost es especialmente conocido por su escalabilidad, eficiencia y precisión. Incorpora técnicas avanzadas como el aumento de gradiente, la regularización y el procesamiento paralelo para mejorar el rendimiento del modelo. Puede manejar una amplia gama de tipos de datos y a menudo se utiliza tanto para problemas de regresión como de clasificación.\n",
    "\n",
    "El algoritmo funciona construyendo de manera iterativa (**secuencial**) árboles de decisión para minimizar una función de pérdida especificada. Cada árbol subsiguiente se enfoca en corregir los errores cometidos por los árboles anteriores, lo que da como resultado un modelo de conjunto altamente preciso. Además, XGBoost permite objetivos de optimización personalizados y métricas de evaluación, lo que proporciona flexibilidad para abordar diversos dominios de problemas.\n",
    "\n",
    "Debido a su rendimiento excepcional y versatilidad, XGBoost ha ganado popularidad en diversos campos, incluidos finanzas, atención médica, marketing y más. Ha sido ampliamente adoptado en competencias de ciencia de datos y es una opción favorita entre los profesionales al abordar problemas complejos de aprendizaje automático."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules\n",
    "import xgboost as xgb\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials # some methods to optimize hyperparameters\n",
    "from hyperopt.pyll import scope"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[FMin](https://github.com/hyperopt/hyperopt/wiki/FMin)\n",
    "\n",
    "## Enfoque del Estimador de Parzen Estructurado en Árbol (TPE) *Tree Parzen Estimator*\n",
    "\n",
    "El Enfoque del Estimador de Parzen Estructurado en Árbol (TPE) es un **algoritmo de optimización bayesiana** utilizado para la sintonización de hiperparámetros en modelos de aprendizaje automático. Es una alternativa popular a los métodos tradicionales de búsqueda en cuadrícula y búsqueda aleatoria. TPE tiene como objetivo explorar eficientemente el espacio de hiperparámetros mediante la exploración y explotación iterativa de las regiones más prometedoras basadas en evaluaciones previas.\n",
    "\n",
    "TPE divide el espacio de búsqueda en dos partes: la **\"prior\"** y la **\"posterior\"**. La \"prior\" representa la **distribución de probabilidad de los hiperparámetros**, mientras que la \"posterior\" refleja la **distribución de probabilidad condicional de los hiperparámetros dados sus valores correspondientes de la función objetivo**.\n",
    "\n",
    "El algoritmo **opera** en un proceso de dos pasos. Primero, construye un modelo probabilístico para estimar la distribución posterior de los hiperparámetros utilizando un conjunto de puntos evaluados previamente. Este modelo se construye típicamente utilizando una estructura de árbol llamada \"ratio de densidad\" que captura las densidades relativas de hiperparámetros que funcionan mejor en comparación con los que funcionan peor.\n",
    "\n",
    "En el segundo paso, TPE genera un nuevo conjunto de hiperparámetros candidatos muestreando de la distribución posterior estimada. La selección de candidatos está sesgada hacia las regiones con una mayor probabilidad de mejorar la función objetivo, aprovechando el conocimiento obtenido de las evaluaciones previas.\n",
    "\n",
    "Al repetir iterativamente estos pasos, TPE explora y refina el espacio de búsqueda de hiperparámetros, convergiendo gradualmente hacia la configuración óptima. Se centra en explorar regiones prometedoras durante las primeras etapas de la optimización y explota esas regiones a medida que avanza la optimización.\n",
    "\n",
    "TPE ha ganado popularidad debido a su capacidad para explorar eficazmente espacios de hiperparámetros de alta dimensionalidad y complejos. Se ha aplicado con éxito en diversos campos, incluyendo el aprendizaje profundo, la selección de modelos de aprendizaje automático y el aprendizaje por refuerzo.\n",
    "\n",
    "### hp\n",
    "\n",
    "En Hyperopt, los hiperparámetros se definen utilizando el módulo \"hp\" proporcionado por la biblioteca. Este módulo ofrece un conjunto de funciones para definir diferentes tipos de hiperparámetros, incluyendo hiperparámetros continuos, discretos y condicionales. Estas funciones permiten la creación de un espacio de búsqueda sobre el cual el algoritmo de optimización puede explorar para encontrar los valores óptimos de los hiperparámetros.\n",
    "\n",
    "### Trials\n",
    "\n",
    "Al pasar directamente un objeto de \"Trials\", podemos inspeccionar todos los valores de retorno que se calcularon durante el experimento.\n",
    "\n",
    "Por ejemplo:\n",
    "\n",
    "- `trials.trials` - una lista de diccionarios que representan todo sobre la búsqueda\n",
    "- `trials.results` - una lista de diccionarios devueltos por 'objective' durante la búsqueda\n",
    "- `trials.losses()` - una lista de pérdidas (flotante para cada prueba 'ok')\n",
    "- `trials.statuses()` - una lista de cadenas de estado\n",
    "\n",
    "Este objeto de \"Trials\" se puede guardar, pasar a las rutinas de trazado incorporadas o analizar con su propio código personalizado.\n",
    "\n",
    "Ahora definamos nuestros conjuntos de datos de entrenamiento y validación y configuremos nuestra ejecución de MLflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = xgb.DMatrix(X_train, label=y_train)\n",
    "valid = xgb.DMatrix(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function - set the parameters for this specific run\n",
    "def objective(params): \n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"model\", \"xgboost\")\n",
    "        mlflow.log_params(params) \n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train, # model trained on training set\n",
    "            num_boost_round=3, # restricted due to time constraints - a value of 1000 iterations is common\n",
    "            evals=[(valid, 'validation')], # model evaluated on validation set\n",
    "            early_stopping_rounds=3 # if no improvements after 3 iterations, stop running # restricted, time constraints\n",
    "        )\n",
    "        y_pred = booster.predict(valid)\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    return {'loss': rmse, 'status': STATUS_OK}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Establecer el rango de búsqueda de optimización del hiperparámetro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [12:25:14] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\objective\\regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:9.19109                          \n",
      "[1]\tvalidation-rmse:8.72924                          \n",
      "[2]\tvalidation-rmse:8.31773                          \n",
      " 33%|███▎      | 1/3 [00:07<00:14,  7.23s/trial, best loss: 8.31773429023806]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [12:25:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\objective\\regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:6.04778                                                  \n",
      "[1]\tvalidation-rmse:5.28118                                                  \n",
      "[2]\tvalidation-rmse:5.10239                                                  \n",
      " 67%|██████▋   | 2/3 [05:10<03:01, 181.46s/trial, best loss: 5.102394266846925]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [12:30:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\objective\\regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:9.00730                                                    \n",
      "[1]\tvalidation-rmse:8.40635                                                    \n",
      "[2]\tvalidation-rmse:7.89389                                                    \n",
      "100%|██████████| 3/3 [05:27<00:00, 109.22s/trial, best loss: 5.102394266846925]\n"
     ]
    }
   ],
   "source": [
    "# Set the range of the hyperparameter optimization search\n",
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)), # tree depth 4 to 100. Returns float, so convert to integer\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, 0), # range exp(-3), exp(0) which is (0.049787, 1.0)\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -1), # range exp(-5), exp(-1) which is (0.006738, 0.367879)\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -6, -1), # range exp(-6), exp(-1) which is (0.002479, 0.367879)\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -1, 3), # range exp(-1), exp(3) which is (0.367879, 20.085537)\n",
    "    'objective': 'reg:linear',\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "\n",
    "best_result = fmin( # imported above\n",
    "    fn=objective,\n",
    "    space=search_space, # as defined above\n",
    "    algo=tpe.suggest, # tpe is the algorithm used for optimization\n",
    "    max_evals=3, #restricted, time constraints\n",
    "    trials=Trials()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*hp.quniform(label, low, high, q)*\n",
    "\n",
    "- Devuelve un valor como round(uniform(low, high) / q) * q\n",
    "- Adecuado para un valor discreto con respecto al cual el objetivo todavía es algo \"suave\", pero que debe estar acotado tanto por encima como por debajo.\n",
    "\n",
    "*hp.loguniform(label, low, high)*\n",
    "\n",
    "- Devuelve un valor dibujado de acuerdo con exp(uniform(low, high)) de modo que el logaritmo del valor de retorno esté distribuido de forma uniforme.\n",
    "- Cuando se optimiza, esta variable está limitada al intervalo [exp(low), exp(high)].\n",
    "\n",
    "Una guía detallada sobre cómo establecer el espacio de búsqueda se incluye en la documentación oficial de Hyperopt.\n",
    "\n",
    "### 2.3.3 Visualizaciones\n",
    "\n",
    "**Vista de tabla**\n",
    "\n",
    "La vista de tabla permite realizar una comparación básica. Puede especificar qué columnas mostrar. En mi caso, podemos ver que el modelo \"brawny-donkey-463\" devuelve el RMSE más bajo, 6.171, una mejora respecto a nuestra cifra de referencia de 9.71.\n",
    "\n",
    "**Vista de gráficos**\n",
    "\n",
    "La vista de gráficos ofrece una visualización ligeramente mejor, un gráfico de barras horizontal. Sin embargo, si queremos comprender completamente nuestros modelos, necesitamos una visualización más compleja que aborde las interrelaciones entre los diversos parámetros y su impacto en el RMSE.\n",
    "\n",
    "**Comparar**\n",
    "\n",
    "Puede filtrar los modelos que desea comparar utilizando \"tags.model=<nombre_del_modelo>\", seleccionarlos todos marcando las casillas y luego hacer clic en \"Comparar\".\n",
    "\n",
    "Explore:\n",
    "\n",
    "**Gráfico de coordenadas paralelas**\n",
    "\n",
    "**Gráfico de dispersión**\n",
    "\n",
    "**Gráfico de contorno**\n",
    "\n",
    "### 2.3.4 Selección del mejor modelo\n",
    "\n",
    "La forma más sencilla de clasificar los modelos es ordenar la columna de **Métricas** de la vista de tabla, sin embargo, no se trata únicamente de la métrica.\n",
    "\n",
    "La velocidad también es algo a considerar. En mi ejemplo simple, aunque el modelo \"brawny-donkey-463\" devolvió el RMSE más bajo, el modelo \"youthful-hen-151\" fue el **más rápido**, con 2.1 segundos. El viejo adagio \"el tiempo es dinero\" es muy cierto en un entorno de producción, por lo que debemos tener en cuenta cuánto tiempo lleva entrenar nuestros modelos.\n",
    "\n",
    "La complejidad del modelo es otro factor. El modelo \"brawny-donkey-463\" es bastante **complejo** con \"max_depth=81\", mientras que el modelo \"youthful-hen-151\" es menos complejo con \"max_depth=11\". Cuanto mayor sea la complejidad, menor será la interpretabilidad. Necesitamos entender lo que nuestro modelo está haciendo \"bajo el capó\" antes de poder explicarlo.\n",
    "\n",
    "### 2.3.5 Entrenando el modelo seleccionado como el mejor\n",
    "\n",
    "Entonces, digamos que después de considerar cuidadosamente las métricas, el tiempo y la complejidad, decidimos optar por el modelo \"brawn-donkey-463\". Podemos tomar sus parámetros y copiarlos en un diccionario de parámetros:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': 0.6379934993414184,\n",
    "    'max_depth': 48,\n",
    "    'min_child_weight': 2.921791686074419,\n",
    "    'objective': 'reg:linear',\n",
    "    'reg_alpha': 0.044409064018651856,\n",
    "    'reg_lambda': 0.00981451912750773,\n",
    "    'seed': 42   \n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes aprovechar [Logging Automático](https://mlflow.org/docs/latest/tracking.html#automatic-logging).\n",
    "\n",
    "### 2.3.6 Logging Automático\n",
    "\n",
    "**El logging automático te permite registrar métricas, parámetros y modelos sin necesidad de declaraciones de registro explícitas.**\n",
    "\n",
    "Hay dos formas de usar el logging automático:\n",
    "\n",
    "1. Llama a mlflow.autolog() antes de tu código de entrenamiento. Esto habilitará el logging automático para cada biblioteca admitida que tengas instalada tan pronto como la importes.\n",
    "\n",
    "2. Usa llamadas específicas de autolog para cada biblioteca que utilices en tu código.\n",
    "\n",
    "Las siguientes bibliotecas admiten la autologización:\n",
    "\n",
    "* Scikit-learn\n",
    "* Keras\n",
    "* Gluon\n",
    "* XGBoost\n",
    "* LightGBM\n",
    "* Statsmodels\n",
    "* Spark\n",
    "* Fastai\n",
    "* Pytorch\n",
    "\n",
    "A continuación, podemos ejecutar el entrenamiento del modelo, en nuestro caso utilizando el prompt de la librería XGBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/10/23 12:30:46 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '3b1b9fb39083421590c9ce62f50d676a', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current xgboost workflow\n",
      "2023/10/23 12:30:48 WARNING mlflow.xgboost: Failed to log dataset information to MLflow Tracking. Reason: Unable to allocate 186. GiB for an array with shape (2421440, 20667) and data type float32\n",
      "c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [12:30:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\objective\\regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:6.15483\n",
      "[1]\tvalidation-rmse:5.35559\n",
      "[2]\tvalidation-rmse:5.16269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/10/23 12:32:40 WARNING mlflow.xgboost: Failed to infer model signature: could not sample data to infer model signature: please ensure that autologging is enabled before constructing the dataset.\n",
      "2023/10/23 12:32:40 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [12:32:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\"\n"
     ]
    }
   ],
   "source": [
    "mlflow.xgboost.autolog()\n",
    "    \n",
    "booster = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=train, # model trained on training set\n",
    "    num_boost_round=3, # restricted due to time constraints - a value of 1000 iterations is common\n",
    "    evals=[(valid, 'validation')], # model evaluated on validation set\n",
    "    early_stopping_rounds=3 # if no improvements after 3 iterations, stop running # restricted, time constraints\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vamos a la interfaz de usuario podemos ver que se ha registrado un nuevo experimento con mucha más información:\n",
    "\n",
    "**busca el nuevo experimento** "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Si miramos las Métricas podemos visualizar la evolución del RMSE.\n",
    "\n",
    "* También tenemos los detalles del modelo por si queremos reproducirlo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Gestión de modelos\n",
    "\n",
    "![Ciclo de MLOps](https://i0.wp.com/neptune.ai/wp-content/uploads/2022/11/MLOps_cycle.webp?resize=1020%2C574&ssl=1)\n",
    "\n",
    "En la sección anterior, examinamos el Seguimiento de Experimentos, pero la gestión de modelos también abarca:\n",
    "\n",
    "- Model Versioning\n",
    "- Model Deployment\n",
    "- Scaling Hardware\n",
    "\n",
    "### 2.4.1 Model Versioning\n",
    "Podríamos usar un sistema de carpetas como una forma muy básica de gestionar las versiones de nuestros modelos, pero esto tiene varias limitaciones.\n",
    "\n",
    "![Sistema de carpetas](https://stephen137.github.io/posts/MLOps_Zoomcamp_Module_2/MLOps_Zoomcamp_Module_2_files/figure-html/ee079e29-1-folders.PNG)\n",
    "\n",
    "Veamos cómo podemos aprovechar MLflow para gestionar el control de versiones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.xgboost.autolog(disable=True) # MLflow will not store parameters automatically - these will have to be requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [12:32:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\objective\\regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:6.15483\n",
      "[1]\tvalidation-rmse:5.35559\n",
      "[2]\tvalidation-rmse:5.16269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [12:34:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\_distutils_hack\\__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    \n",
    "    train = xgb.DMatrix(X_train, label=y_train)\n",
    "    valid = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "    best_params = {\n",
    "        'learning_rate': 0.4434065752589766,\n",
    "        'max_depth': 81,\n",
    "        'min_child_weight': 10.423237853746643,\n",
    "        'objective': 'reg:linear',\n",
    "        'reg_alpha': 0.2630756846813668,\n",
    "        'reg_lambda': 0.1220536223877784,\n",
    "        'seed': 42    \n",
    "    }\n",
    "\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    booster = xgb.train(\n",
    "        params=params,\n",
    "        dtrain=train, # model trained on training set\n",
    "        num_boost_round=3, # restricted due to time constraints - a value of 1000 iterations is common\n",
    "        evals=[(valid, 'validation')], # model evaluated on validation set\n",
    "        early_stopping_rounds=3 # if no improvements after 3 iterations, stop running # restricted, time constraints\n",
    "        )\n",
    "\n",
    "    y_pred = booster.predict(valid)\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    with open(\"models/preprocessor.b\", \"wb\") as f_out: # save pre-processing as a model\n",
    "        pickle.dump(dv, f_out)\n",
    "        \n",
    "    mlflow.log_artifact(\"models/preprocessor.b\", artifact_path=\"preprocessor\") # we can isolate the pre-processing from raw data\n",
    "    mlflow.xgboost.log_model(booster, artifact_path=\"models_mlflow\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ejecutar esto, podemos ver desde la interfaz de usuario que tanto el modelo XGBoost como un modelo de preprocesamiento se han guardado. Más tarde, esto se puede cargar para procesar los datos de predicción y luego pasarlos a través del modelo XGBoost.\n",
    "\n",
    "**models_mlflow**\n",
    "\n",
    "### 2.4.2 Realización de predicciones\n",
    "\n",
    "MLflow proporciona fragmentos de código útiles para realizar predicciones en un DataFrame de Spark o pandas.\n",
    "\n",
    "Vamos a usar el fragmento de pandas y hacer una predicción. Primero, carguemos el modelo. Hay dos sabores disponibles, `python_function` o, alternativamente, `xgboost`.\n",
    "\n",
    "`python_function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/10/23 12:35:01 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - mlflow (current: 2.7.1, required: mlflow==2.4)\n",
      " - numpy (current: 1.26.0, required: numpy==1.25.1)\n",
      " - pandas (current: 2.1.1, required: pandas==2.0.3)\n",
      " - psutil (current: 5.9.5, required: psutil==5.9.0)\n",
      " - scikit-learn (current: 1.3.1, required: scikit-learn==1.3.0)\n",
      " - scipy (current: 1.11.2, required: scipy==1.11.1)\n",
      " - typing-extensions (current: 4.8.0, required: typing-extensions==4.7.1)\n",
      " - xgboost (current: 2.0.0, required: xgboost==1.7.6)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n",
      "2023/10/23 12:35:02 WARNING mlflow.pyfunc: The version of Python that the model was saved in, `Python 3.10.12`, differs from the version of Python that is currently running, `Python 3.9.7`, and may be incompatible\n",
      "c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [12:35:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\objective\\regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "logged_model = 'file:///c:/Users/marti/Desktop/CursoSadosky/MLops/mlruns/4/feaddbda7d3a4138bcd6b4f8db1f6f44/artifacts/models_mlflow'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  artifact_path: models_mlflow\n",
       "  flavor: mlflow.xgboost\n",
       "  run_id: feaddbda7d3a4138bcd6b4f8db1f6f44"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model = mlflow.xgboost.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xgboost.core.Booster at 0x22c9d90f4c0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can make predictions with this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgboost_model.predict(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.847052 , 17.987246 , 24.64872  , 25.763891 , 29.417316 ,\n",
       "       12.618283 , 23.466017 ,  5.1277075, 15.760189 , 16.288137 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the first 10\n",
    "y_pred[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumiendo esta sección, hemos visto que es posible tomar un modelo entrenado utilizando una variedad de bibliotecas diferentes y registrar ese modelo en MLflow. Luego, puede acceder a ese modelo utilizando diferentes \"flavors\", como una función de Python o un modelo de scikit-learn. Luego, se vuelve muy fácil realizar predicciones y posteriormente implementar el modelo, por ejemplo, como una función de Python, en un contenedor Docker, en un cuaderno Jupyter o tal vez como un trabajo por lotes en Spark. Además, puede implementar en un clúster de Kubernetes o en diferentes entornos en la nube, como Amazon SageMaker o Microsoft Azure.\n",
    "\n",
    "![Formato del modelo](https://stephen137.github.io/posts/MLOps_Zoomcamp_Module_2/MLOps_Zoomcamp_Module_2_files/figure-html/dceee7a2-1-model_format.PNG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Registro de modelos\n",
    "### 2.5.1 Motivación\n",
    "Imagina que eres un ingeniero de aprendizaje automático o MLOps y recibes el siguiente correo electrónico de un científico de datos:\n",
    "\n",
    "![Correo electrónico](https://stephen137.github.io/posts/MLOps_Zoomcamp_Module_2/MLOps_Zoomcamp_Module_2_files/figure-html/165e93d0-1-model_registry.PNG)\n",
    "\n",
    "Existen varias preguntas sin respuesta que deben resolverse antes de que te sientas cómodo al implementar el modelo, como:\n",
    "\n",
    "- ¿Qué ha cambiado desde la versión anterior?\n",
    "- ¿Es necesario actualizar los hiperparámetros?\n",
    "- ¿Se necesita algún preprocesamiento?\n",
    "- ¿Cuáles son las dependencias necesarias para ejecutar el modelo?\n",
    "\n",
    "Con el fin de evitar retrasos en la implementación del modelo debido a correspondencia por correo electrónico larga o ambigüedad, podemos aprovechar el Registro de Modelos de MLflow.\n",
    "\n",
    "![Registro de modelos](https://stephen137.github.io/posts/MLOps_Zoomcamp_Module_2/MLOps_Zoomcamp_Module_2_files/figure-html/218f3014-1-register_model.PNG)\n",
    "\n",
    "Ten en cuenta que el registro de modelos no equivale a la implementación. Es una \"sala de espera\" de modelos que se asignarán a etapas de puesta en escena, producción o archivo. Para implementar realmente un modelo, necesitaríamos algún código de CI/CD (integración continua y entrega continua).\n",
    "\n",
    "### 2.5.2 Registro de un modelo\n",
    "Bueno, digamos que estamos contentos con nuestra ejecución whimsical-shad-190, que fue un modelo XGBoost, y ahora queremos moverlo a la etapa de puesta en escena. Para hacerlo, haz clic en Registrar modelo y dale un nombre al modelo:\n",
    "\n",
    "**Registrar modelo con el nombre mlops_nyc_taxi**\n",
    "\n",
    "Cuando vamos a la pestaña de Modelos, ahora podemos ver nuestro modelo registrado.\n",
    "\n",
    "### 2.5.3 Transición de etapa\n",
    "Mencionamos anteriormente que existen tres etapas: Puesta en Escena, Producción y Archivo. Como se puede ver arriba, nuestro modelo está recién registrado y aún no ha sido trasladado. Podemos hacer esto haciendo clic primero en la versión que deseamos poner en escena, lo que nos lleva a esta pantalla.\n",
    "\n",
    "Haz clic en Transición a -> Puesta en Escena y si regresamos a nuestra pestaña de modelos, podemos ver que ahora se muestra en la columna de Puesta en Escena.\n",
    "\n",
    "### 2.5.4 Interacción con el servidor de seguimiento de MLflow\n",
    "El módulo mlflow.client proporciona una interfaz CRUD de Python para Experimentos, Ejecuciones, Versiones de Modelos y Modelos Registrados de MLflow. Esta es una API de nivel inferior que se traduce directamente en llamadas a la API REST de MLflow. Para una API de nivel superior para administrar una \"ejecución activa\", utiliza el módulo mlflow.\n",
    "\n",
    "Esencialmente, esto nos permite interactuar con la interfaz de usuario de MLflow y acceder a la misma información utilizando Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_TRACKING_URI = \"sqlite:///mlflow.db\"\n",
    "\n",
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imaginemos que intentamos comprender, para un experimento determinado, cuáles son los mejores modelos o ejecuciones:\n",
    "\n",
    "**Buscar id del experiment que inicializamos y colocarlo en experiment_ids**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.entities import ViewType\n",
    "\n",
    "runs = client.search_runs(\n",
    "    experiment_ids='4', # mlops_nyc_taxi\n",
    "    filter_string=\"metrics.rmse < 10\", # grab only the runs with an RMSE below 10\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    max_results=5,\n",
    "    order_by=[\"metrics.rmse ASC\"] # Ascending\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id: 37a5bb0dc7e84499ac8a8eeb6ecea675, rmse: 5.1024\n",
      "run id: cf1de24cf10d46749b3dcfd5e0a3b1b1, rmse: 5.1352\n",
      "run id: c77ad7dc58194ebdb99a736642d2ff2a, rmse: 5.1627\n",
      "run id: f5caede9e9b6414ca8801a629c8e2811, rmse: 5.1627\n",
      "run id: b1df062a8dc64dc49cc1b9a78f798109, rmse: 5.2820\n"
     ]
    }
   ],
   "source": [
    "for run in runs:\n",
    "    print(f\"run id: {run.info.run_id}, rmse: {run.data.metrics['rmse']:.4f}\") # round to 4 d.p"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.5 Interactuando con el Registro de Modelos\n",
    "En esta sección, utilizaremos la instancia de MlflowClient para:\n",
    "\n",
    "* Registrar una nueva versión para el experimento mlops_nyc_taxi\n",
    "* Recuperar las últimas versiones del modelo nyc_taxi_xgb y verificar que se haya creado una nueva versión\n",
    "* Transicionar la nueva versión 2 a \"Puesta en Escena\"\n",
    "* Agregar anotaciones\n",
    "\n",
    "Registrar una nueva versión para el experimento mlops_nyc_taxi\n",
    "\n",
    "**Analizar pestaña Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'mlops_nyc_taxi_1' already exists. Creating a new version of this model...\n",
      "2023/10/23 12:35:04 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: mlops_nyc_taxi_1, version 6\n",
      "Created version '6' of model 'mlops_nyc_taxi_1'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1698075304014, current_stage='None', description=None, last_updated_timestamp=1698075304014, name='mlops_nyc_taxi_1', run_id='feaddbda7d3a4138bcd6b4f8db1f6f44', run_link=None, source='file:///c:/Users/marti/Desktop/CursoSadosky/MLops/mlruns/4/feaddbda7d3a4138bcd6b4f8db1f6f44/artifacts/model', status='READY', status_message=None, tags={}, user_id=None, version=6>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# register the top performing model(run) from the mlops_nyc_taxi experiment\n",
    "run_id = \"feaddbda7d3a4138bcd6b4f8db1f6f44\" \n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "mlflow.register_model(model_uri=model_uri, name=\"mlops_nyc_taxi_1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que ahora tenemos la versión 2 de nuestro modelo.\n",
    "\n",
    "Recuperar las últimas versiones del modelo nyc_taxi_xgb y comprobar que se ha creado una nueva versión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: 1, stage: Production\n",
      "version: 2, stage: Staging\n"
     ]
    }
   ],
   "source": [
    "model_name = \"nyc_taxi_xgb\"\n",
    "latest_versions = client.get_latest_versions(name=model_name)\n",
    "\n",
    "for version in latest_versions:\n",
    "    print(f\"version: {version.version}, stage: {version.current_stage}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transición de la nueva versión 2 a \"Staging\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1689178215523, current_stage='Staging', description='The model version 2 was transitioned to Staging on 2023-09-22', last_updated_timestamp=1698075304102, name='nyc_taxi_xgb', run_id='52579390d9714d83b395be8615e0e851', run_link='', source='file:///c:/Users/marti/Desktop/CursoSadosky/MLops/mlruns/1/52579390d9714d83b395be8615e0e851/artifacts/model', status='READY', status_message=None, tags={}, user_id=None, version=2>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_version = 2\n",
    "new_stage = \"Staging\"\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    "    stage=new_stage,\n",
    "    archive_existing_versions=False # so version 1 will remain in Staging\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que esto se ha realizado exitosamente.\n",
    "\n",
    "**both in staggning area**\n",
    "\n",
    "Agregar anotaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1689178215523, current_stage='Staging', description='The model version 2 was transitioned to Staging on 2023-10-23', last_updated_timestamp=1698075304133, name='nyc_taxi_xgb', run_id='52579390d9714d83b395be8615e0e851', run_link='', source='file:///c:/Users/marti/Desktop/CursoSadosky/MLops/mlruns/1/52579390d9714d83b395be8615e0e851/artifacts/model', status='READY', status_message=None, tags={}, user_id=None, version=2>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "date = datetime.today().date()\n",
    "client.update_model_version(\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    "    description=f\"The model version {model_version} was transitioned to {new_stage} on {date}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ver anotaciones en la descripción de mlflow**\n",
    "\n",
    "Añadamos la Versión 1 a Producción para utilizarla en la ilustración que sigue en la siguiente sección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1689178043596, current_stage='Production', description='The model version 1 was transitioned to Production on 2023-10-23', last_updated_timestamp=1698075304180, name='nyc_taxi_xgb', run_id='e5f0b90fde45451a85f5fe4bc7c3bd08', run_link=None, source='file:///c:/Users/marti/Desktop/CursoSadosky/MLops/mlruns/1/e5f0b90fde45451a85f5fe4bc7c3bd08/artifacts/model', status='READY', status_message=None, tags={}, user_id=None, version=1>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_version = 1\n",
    "new_stage = \"Production\"\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    "    stage=new_stage,\n",
    "    archive_existing_versions=False # \n",
    ")\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "date = datetime.today().date()\n",
    "client.update_model_version(\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    "    description=f\"The model version {model_version} was transitioned to {new_stage} on {date}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.6 Comparing versions and selecting the new “Production” model\n",
    "En esta última sección, recuperaremos los modelos registrados en el registro de modelos y compararemos su rendimiento en un conjunto de prueba no visto. La idea es simular el escenario en el que un ingeniero de implementación tiene que interactuar con el registro de modelos para decidir si actualizar o no la versión del modelo que está en producción.\n",
    "\n",
    "Estos son los pasos:\n",
    "\n",
    "* Cargar el conjunto de datos de prueba, que corresponde a los datos de los taxis amarillos de Nueva York del mes de marzo de 2022.\n",
    "* Descargar el DictVectorizer que se ajustó utilizando los datos de entrenamiento y se guardó en MLflow como un artefacto, y cargarlo con pickle.\n",
    "* Procesar el conjunto de pruebas utilizando el DictVectorizer.\n",
    "* Realizar predicciones en el conjunto de pruebas utilizando la versión del modelo que actualmente está en la etapa de \"Producción\".\n",
    "* Basándonos en los resultados, actualizar la versión del modelo en \"Producción\" en consecuencia.\n",
    "\n",
    "**Registro de modelos**\n",
    "\n",
    "El registro de modelos en realidad no implementa el modelo en producción cuando se transfiere un modelo a la etapa de \"Producción\", simplemente asigna una etiqueta a esa versión del modelo. Debe complementar el registro con algún código de CI/CD que realice la implementación real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download March 2022 yellow taxi data as `test` dataset\n",
    "# we used Feb 2022 for validation (which is sometimes also effectively the 'test' set)\n",
    "\n",
    "# !wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our functions\n",
    "\n",
    "def read_dataframe(filename):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "        df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "        df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "    elif filename.endswith('.parquet'):\n",
    "        df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocess(df, dv):\n",
    "    df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n",
    "    categorical = ['PU_DO']\n",
    "    numerical = ['trip_distance']\n",
    "    train_dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "    return dv.transform(train_dicts) # not fitting the pre-processor again\n",
    "\n",
    "\n",
    "def test_model(name, stage, X_test, y_test):\n",
    "    model = mlflow.pyfunc.load_model(f\"models:/{name}/{stage}\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    return {\"rmse\": mean_squared_error(y_test, y_pred, squared=False)}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargue el conjunto de datos de prueba, que corresponde a los datos de NYC Yellow Taxi del mes de marzo de 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_dataframe(\"yellow_tripdata_2022-03.parquet\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descargue el DictVectorizer que fue ajustado utilizando los datos de entrenamiento y guardado en MLflow como un artefacto, y cárguelo con pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|██████████| 1/1 [00:00<00:00, 38.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\marti\\\\Desktop\\\\CursoSadosky\\\\MLops\\\\preprocessor'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.download_artifacts(run_id=run_id, path='preprocessor', dst_path='.') # downloaded locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator DictVectorizer from version 1.3.0 when using version 1.3.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"preprocessor/preprocessor.b\", \"rb\") as f_in:\n",
    "    dv = pickle.load(f_in)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesar el conjunto de pruebas con el DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = preprocess(df, dv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar predicciones sobre el conjunto de pruebas - modelo en Producción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"duration\"\n",
    "y_test = df[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/10/23 12:35:55 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - mlflow (current: 2.7.1, required: mlflow==2.4)\n",
      " - numpy (current: 1.26.0, required: numpy==1.25.1)\n",
      " - pandas (current: 2.1.1, required: pandas==2.0.3)\n",
      " - psutil (current: 5.9.5, required: psutil==5.9.0)\n",
      " - scikit-learn (current: 1.3.1, required: scikit-learn==1.3.0)\n",
      " - scipy (current: 1.11.2, required: scipy==1.11.1)\n",
      " - typing-extensions (current: 4.8.0, required: typing-extensions==4.7.1)\n",
      " - xgboost (current: 2.0.0, required: xgboost==1.7.6)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n",
      "2023/10/23 12:35:55 WARNING mlflow.pyfunc: The version of Python that the model was saved in, `Python 3.10.12`, differs from the version of Python that is currently running, `Python 3.9.7`, and may be incompatible\n",
      "c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [12:35:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0cec3277c4d9d0165-1\\xgboost\\xgboost-ci-windows\\src\\objective\\regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# From the experiments, model script\n",
    "logged_model = 'runs:/feaddbda7d3a4138bcd6b4f8db1f6f44/models_mlflow'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on a Pandas DataFrame.\n",
    "import pandas as pd\n",
    "y_predict=loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.561789023449282"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_predict, squared=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así pues, el RMSE es sólo ligeramente superior (6,505) y el rendimiento es ligeramente peor cuando se prueba con los datos no vistos de marzo de 2022 que con la métrica del conjunto de validación (6,171)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 MLflow en la práctica\n",
    "Consideremos tres escenarios:\n",
    "\n",
    "1. Un único científico de datos participando en una competencia de ML.\n",
    "2. Un equipo interdisciplinario con un científico de datos trabajando en un modelo de ML.\n",
    "3. Múltiples científicos de datos trabajando en múltiples modelos de ML.\n",
    "\n",
    "### 2.6.1 Un único científico de datos participando en una competencia de ML\n",
    "En este caso de uso, tener un servidor de seguimiento remoto sería excesivo. No es necesario compartir información con otros y usar un registro de modelos sería inútil, porque no hay posibilidad de implementación del modelo en producción.\n",
    "\n",
    "Configuración de MLflow:\n",
    "\n",
    "* Servidor de seguimiento: no\n",
    "* Almacenamiento de backend: sistema de archivos local\n",
    "* Almacenamiento de artefactos: sistema de archivos local\n",
    "\n",
    "Los experimentos se pueden explorar localmente iniciando la interfaz de usuario de MLflow.\n",
    "\n",
    "### 2.6.2 Un equipo interdisciplinario con un científico de datos trabajando en un modelo de ML\n",
    "La información deberá compartirse con el equipo interdisciplinario, pero no necesariamente hay necesidad de ejecutar un servidor de seguimiento de forma remota; localmente puede ser suficiente. Usar el registro de modelos podría ser una buena idea para gestionar el ciclo de vida de los modelos, pero no está claro si necesitamos ejecutarlo de forma remota o en el host local.\n",
    "\n",
    "Configuración de MLflow:\n",
    "\n",
    "* Servidor de seguimiento: sí, servidor local\n",
    "* Almacenamiento de backend: base de datos sqlite\n",
    "* Almacenamiento de artefactos: sistema de archivos local\n",
    "\n",
    "Los experimentos se pueden explorar localmente accediendo al servidor de seguimiento local.\n",
    "\n",
    "Para ejecutar este ejemplo, debe iniciar el servidor de MLflow localmente ejecutando el siguiente comando en su terminal:\n",
    "\n",
    "!mlflow server --backend-store-uri sqlite:///backend.db\n",
    "\n",
    "### 2.6.3 Múltiples científicos de datos trabajando en múltiples modelos de ML\n",
    "Compartir información es muy importante en este escenario. Existe colaboración entre científicos para construir modelos y, por lo tanto, necesitan un servidor de seguimiento remoto y deben hacer uso del registro de modelos.\n",
    "\n",
    "Configuración de MLflow:\n",
    "\n",
    "* Servidor de seguimiento: sí, servidor remoto (EC2)\n",
    "* Almacenamiento de backend: base de datos postgresql\n",
    "* Almacenamiento de artefactos: cubo de s3\n",
    "\n",
    "Los experimentos se pueden explorar accediendo al servidor remoto.\n",
    "\n",
    "El ejemplo utiliza AWS para alojar un servidor remoto. Para ejecutar el ejemplo, necesitará una cuenta de AWS. Siga los pasos descritos a continuación para crear una nueva cuenta de AWS y lanzar el servidor de seguimiento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
