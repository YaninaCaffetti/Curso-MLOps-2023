{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ciencia de Datos e Inteligencia Artificial para la industria del software**\n",
    "\n",
    "# *Curso MLOps*\n",
    "\n",
    "## **Edición 2023**\n",
    "\n",
    "# 4. Despliegue de Modelos\n",
    "\n",
    "El despliegue de modelos es el proceso de poner modelos de aprendizaje automático en producción. Esto pone las predicciones del modelo a disposición de los usuarios, desarrolladores o sistemas, para que puedan tomar decisiones comerciales basadas en datos, interactuar con su aplicación (como reconocer una cara en una imagen) y más.\n",
    "\n",
    "El despliegue de modelos se considera una etapa desafiante para los científicos de datos. Esto se debe a que a menudo no se considera su responsabilidad principal y debido a las diferencias tecnológicas y de mentalidad entre el desarrollo y entrenamiento del modelo y la infraestructura tecnológica y organizativa, como la gestión de versiones, pruebas y escalabilidad, que hacen que el despliegue sea complicado. Estos silos organizativos y tecnológicos pueden superarse con los marcos, herramientas y procesos adecuados para el despliegue de modelos.\n",
    "\n",
    "Una vez que tenemos nuestro modelo entrenado, es necesario llevarlo a producción. A continuación, exploraremos algunas formas de hacer este despliegue y aplicaremos un enfoque local.\n",
    "\n",
    "## 4.1 Tres formas de desplegar un modelo\n",
    "\n",
    "* Principalmente, existen dos tipos de despliegues:\n",
    "    * Por lotes (offline) - se ejecuta regularmente\n",
    "    * En línea - Siempre en funcionamiento con dos subopciones:\n",
    "        * Servicio web\n",
    "        * Streaming\n",
    "\n",
    "**Por lotes - Offline:**\n",
    "\n",
    "El despliegue offline o por lotes es una estrategia de despliegue utilizada en el contexto de modelos de aprendizaje automático, particularmente cuando se necesita realizar predicciones o inferencias en un conjunto de datos de gran tamaño, no en tiempo real o de forma asíncrona. Este enfoque se utiliza típicamente cuando la latencia de las predicciones en tiempo real no es una preocupación crítica y puede permitirse procesar datos por lotes.\n",
    "\n",
    "* Se utiliza para casos de uso donde las actividades que admite no ocurren en tiempo real pero pueden agruparse.\n",
    "    * Por ejemplo, si estoy enviando ofertas promocionales a los usuarios basadas en su probabilidad de abandono de mi servicio, puedo hacerlo diariamente.\n",
    "\n",
    "Si podemos esperar un poco para obtener nuestras predicciones. Luego, predecimos periódicamente nuevos datos. Tenemos una base de datos y un trabajo de puntuación. El trabajo de puntuación extrae periódicamente datos de la base de datos y ejecuta el modelo en ellos. El resultado se guarda en una base de datos de predicciones.\n",
    "\n",
    "**En línea - Servicio web:**\n",
    "\n",
    "El despliegue en línea o como servicio web es una estrategia de despliegue para modelos de aprendizaje automático en la que el modelo se expone como un servicio web, lo que permite realizar predicciones o inferencias en tiempo real a través de llamadas a API (Interfaz de Programación de Aplicaciones). \n",
    "Este enfoque es particularmente útil cuando se requieren respuestas en tiempo real de baja latencia, como en aplicaciones como chatbots, sistemas de recomendación, detección de fraudes y más.\n",
    "\n",
    "El modelo siempre está disponible para hacer predicciones. Hay dos formas de desplegar un modelo en línea:\n",
    "\n",
    "**Servicio web:**\n",
    "Esta relación produce una relación 1:1 entre el cliente (BackendService) y el servidor (DurationPredictionService), que se mantiene activa solo durante el tiempo que lleva procesar la solicitud.\n",
    "\n",
    "**Streaming:**\n",
    "En el caso de uso de streaming, el concepto se basa en el servicio web al desacoplar el cliente del servidor y establecer una relación de muchos a muchos entre los productores y consumidores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación de despliegue de un modelo como servicio web\n",
    "\n",
    "* Creación de un **entorno virtual** con Pipenv\n",
    "* Creación de un script para hacer predicciones\n",
    "* Transformación del script en una **aplicación Flask**\n",
    "* Empaquetamiento de la aplicación en **Docker**\n",
    "\n",
    "A partir de un archivo .pkl, exportaremos el modelo como un servicio web.\n",
    "\n",
    "### Entorno virtual\n",
    "\n",
    "Un entorno virtual es una herramienta que ayuda a mantener separadas las dependencias requeridas por diferentes proyectos creando entornos virtuales de Python aislados para ellos. Esta es una de las herramientas más importantes que utilizan la mayoría de los desarrolladores de Python.\n",
    "\n",
    "**¿Por qué necesitamos un entorno virtual?**\n",
    "\n",
    "Imagina un escenario en el que estás trabajando en dos proyectos web en Python, uno de ellos utiliza Django 4.0 y el otro utiliza Django 4.1. En tales situaciones, el entorno virtual puede ser realmente útil para mantener las dependencias de ambos proyectos.\n",
    "\n",
    "**Cuándo y dónde usar un entorno virtual?**\n",
    "\n",
    "Por defecto, todos los proyectos en tu sistema utilizarán estos mismos directorios para almacenar y recuperar los paquetes del sitio (bibliotecas de terceros). ¿Por qué esto importa? Ahora, en el ejemplo anterior de dos proyectos, tienes dos versiones de Django. Este es un problema real para Python, ya que no puede diferenciar entre las versiones en el directorio de \"site-packages\". Aquí es donde entran en juego los entornos virtuales. Para resolver este problema, simplemente necesitamos crear dos entornos virtuales separados para ambos proyectos. Lo genial de esto es que no hay límites en la cantidad de entornos que puedes tener, ya que son solo directorios que contienen algunos scripts. Se debe utilizar un entorno virtual cada vez que trabajas en cualquier proyecto basado en Python. Por lo general, es bueno tener un nuevo entorno virtual para cada proyecto basado en Python en el que trabajes. De esta manera, las dependencias de cada proyecto están aisladas del sistema y de los demás.\n",
    "\n",
    "**¿Cómo funciona un entorno virtual?**\n",
    "\n",
    "Usamos un módulo llamado virtualenv, que es una herramienta para crear entornos Python aislados. virtualenv crea una carpeta que contiene todos los ejecutables necesarios para usar los paquetes que un proyecto de Python necesitaría.\n",
    "\n",
    "### Flask\n",
    "\n",
    "Flask es un marco web. Esto significa que Flask te proporciona herramientas, bibliotecas y tecnologías que te permiten construir una aplicación web. Esta aplicación web puede ser algunas páginas web, un blog, una wiki o puede ser tan grande como una aplicación de calendario basada en la web o un sitio web comercial.\n",
    "\n",
    "Flask forma parte de la categoría de los micro marcos. Los micro marcos son normalmente marcos con pocas o ninguna dependencia de bibliotecas externas. Esto tiene pros y contras. Los pros son que el marco es ligero, hay pocas dependencias que actualizar y controlar en busca de errores de seguridad, los contras son que a veces tendrás que hacer más trabajo por ti mismo o aumentar la lista de dependencias agregando complementos. En el caso de Flask, sus dependencias son:\n",
    "\n",
    "* Werkzeug, una biblioteca de utilidades WSGI.\n",
    "* Jinja2, que es su motor de plantillas.\n",
    "\n",
    "### Docker\n",
    "\n",
    "Docker es una plataforma abierta para desarrollar, enviar y ejecutar aplicaciones. Docker te permite separar tus aplicaciones de tu infraestructura para que puedas entregar software rápidamente. Con Docker, puedes administrar tu infraestructura de la misma manera que administras tus aplicaciones. Al aprovechar las metodologías de Docker para enviar, probar y implementar código, puedes reducir significativamente el retraso entre escribir código y ejecutarlo en producción.\n",
    "\n",
    "**La plataforma Docker**\n",
    "\n",
    "Docker proporciona la capacidad de empacar y ejecutar una aplicación en un entorno aislado denominado contenedor. El aislamiento y la seguridad te permiten ejecutar muchos contenedores simultáneamente en un host determinado. Los contenedores son livianos y contienen todo lo necesario para ejecutar la aplicación, por lo que no es necesario depender de lo que esté instalado en el host. Puedes compartir contenedores mientras trabajas y estar seguro de que todos con los que compartes obtienen el mismo contenedor que funciona de la misma manera.\n",
    "\n",
    "Docker proporciona herramientas y una plataforma para administrar el ciclo de vida de tus contenedores:\n",
    "\n",
    "* Desarrolla tu aplicación y sus componentes de soporte utilizando contenedores.\n",
    "* El contenedor se convierte en la unidad para distribuir y probar tu aplicación.\n",
    "* Cuando estés listo, implementa tu aplicación en tu entorno de producción, ya sea como un contenedor o como un servicio orquestado. Esto funciona de la misma manera, ya sea que tu entorno de producción sea un centro de datos local, un proveedor de la nube o una combinación de ambos.\n",
    "\n",
    "**¿Para qué puedo usar Docker?**\n",
    "\n",
    "*Entrega rápida y consistente de tus aplicaciones*\n",
    "\n",
    "Docker agiliza el ciclo de desarrollo al permitir que los desarrolladores trabajen en entornos estandarizados utilizando contenedores locales que proporcionan tus aplicaciones y servicios. Los contenedores son ideales para flujos de trabajo de integración continua y entrega continua (CI/CD).\n",
    "\n",
    "Considera el siguiente escenario de ejemplo:\n",
    "\n",
    "* Tus desarrolladores escriben código localmente y comparten su trabajo con sus colegas utilizando contenedores Docker.\n",
    "* Utilizan Docker para implementar sus aplicaciones en un entorno de prueba y ejecutan pruebas automáticas y manuales.\n",
    "* Cuando los desarrolladores encuentran errores, pueden corregirlos en el entorno de desarrollo y volver a implementarlos en el entorno de prueba para su prueba y validación.\n",
    "* Una vez que la prueba esté completa, llevar la corrección al cliente es tan simple como enviar la imagen actualizada al entorno de producción.\n",
    "\n",
    "**Implementación y escalado receptivos**\n",
    "\n",
    "La plataforma basada en contenedores de Docker permite cargas de trabajo altamente portátiles. Los contenedores Docker pueden ejecutarse en el portátil de un desarrollador, en máquinas físicas o virtuales en un centro de datos, en proveedores de la nube o en una combinación de entornos.\n",
    "\n",
    "La portabilidad y naturaleza ligera de Docker también facilitan la administración dinámica de cargas de trabajo, escalando aplicaciones y servicios hacia arriba o hacia abajo según lo requieran las necesidades comerciales, en tiempo casi real.\n",
    "\n",
    "**Ejecutar más cargas de trabajo en el mismo hardware**\n",
    "\n",
    "Docker es ligero y rápido. Proporciona una alternativa viable y rentable a las máquinas virtuales basadas en hipervisor, lo que te permite utilizar más capacidad de tu servidor para lograr tus objetivos comerciales. Docker es perfecto para entornos de alta densidad y para implementaciones pequeñas y medianas donde necesitas hacer más con menos recursos.\n",
    "\n",
    "## Despliegue de un modelo como servicio web\n",
    "\n",
    "#### **Paso 1**\n",
    "\n",
    "Como mencioné anteriormente (y si no lo mencioné antes, lo digo ahora, pero debería haberlo mencionado antes), trabajar con Windows en este tipo de problemas es sumamente complicado y se recomienda trabajar con **LINUX** (nuestro salvador). Pero como sería muy difícil que todos instalaran Linux para tan pocas clases, por eso he decidido adaptarlo para darles las nociones necesarias para abordar estos problemas cuando sea necesario, implementando Windows.\n",
    "\n",
    "**Instalar Windows PowerShell**\n",
    "\n",
    "[Tutorial](https://learn.microsoft.com/es-es/powershell/scripting/install/installing-powershell-on-windows?view=powershell-7.3)\n",
    "\n",
    "En primer lugar, debemos determinar cuál es la versión de scikit-learn con la que entrenamos nuestro modelo en la primera clase para evitar problemas de versiones entre nuestro modelo empaquetado y el entorno.\n",
    "\n",
    "#### **Paso 2**\n",
    "\n",
    "Instalar **Pipenv**:\n",
    "\n",
    "1. Abre un símbolo del sistema (Command Prompt) presionando Win + R, escribe cmd y presiona Enter. Luego, ejecuta el siguiente comando para instalar Pipenv:\n",
    "\n",
    "\n",
    "```bash\n",
    "pip install pipenv\n",
    "```\n",
    "\n",
    "Esto instalará Pipenv en tu sistema.\n",
    "\n",
    "2. Agregar rutas de Pipenv a la variable de entorno PATH: Debes agregar directorios específicos a la variable de entorno PATH para que el sistema pueda encontrar los archivos ejecutables de Pipenv. Reemplaza `<username>` en las siguientes rutas con tu nombre de usuario de Windows:\n",
    "\n",
    "* `C:\\Users\\<username>\\AppData\\Roaming\\Python\\Python310\\Scripts`\n",
    "* `C:\\Users\\<username>\\AppData\\Roaming\\Python\\Python310\\site-packages`\n",
    "\n",
    "Aquí, `Python310` debe reemplazarse con tu versión de Python, en este caso, Python 3.10. Para agregar estas rutas a tu variable de entorno PATH, sigue estos pasos:\n",
    "\n",
    "a. Presiona Win + S, escribe \"Variables de entorno\" y selecciona \"Editar las variables de entorno del sistema\".\n",
    "\n",
    "b. En la ventana \"Propiedades del sistema\", haz clic en el botón \"Variables de entorno\".\n",
    "\n",
    "c. En la ventana \"Variables de entorno\", bajo la sección \"Variables de usuario\", busca la variable \"Path\", selecciónala y haz clic en el botón \"Editar\".\n",
    "\n",
    "d. En la ventana \"Editar variable de entorno\", haz clic en el botón \"Nuevo\" y luego agrega las dos rutas mencionadas anteriormente, una a la vez. Haz clic en \"Aceptar\" después de agregar cada ruta.\n",
    "\n",
    "e. Haz clic en \"Aceptar\" para cerrar todas las ventanas.\n",
    "\n",
    "Debería verse algo así (reemplaza `<username>` y `<Python310>` según corresponda):\n",
    "\n",
    "> C:\\Users\\<username>\\AppData\\Roaming\\Python\\Python310\\Scripts\n",
    "> C:\\Users\\<username>\\AppData\\Roaming\\Python\\Python310\\site-packages\n",
    "\n",
    "\n",
    "3. Cerrar y volver a abrir el símbolo del sistema: Después de cambiar la variable de entorno PATH, es importante cerrar el símbolo del sistema (si estaba abierto) y volver a abrirlo. Esto asegura que los cambios surtan efecto.\n",
    "\n",
    "4. Verificar la instalación: Para comprobar si Pipenv se instaló correctamente, abre un nuevo símbolo del sistema y ejecuta:\n",
    "\n",
    "```bash\n",
    "pipenv --version\n",
    "```\n",
    "\n",
    "Si Pipenv está instalado y configurado correctamente, este comando debería mostrar la versión de Pipenv instalada.\n",
    "\n",
    "Siguiendo estos pasos, deberías haber instalado Pipenv en Windows y agregado las rutas necesarias a tu variable de entorno PATH para usarlo cómodamente con Python 3.10.\n",
    "\n",
    "#### **Paso 3**\n",
    "\n",
    "Comprueba la versión de scikit-learn con la que entrenamos nuestro modelo predictivo en la primera clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: scikit-learn\n",
      "Version: 1.3.1\n",
      "Summary: A set of python modules for machine learning and data mining\n",
      "Home-page: http://scikit-learn.org\n",
      "Author: \n",
      "Author-email: \n",
      "License: new BSD\n",
      "Location: c:\\users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\n",
      "Requires: joblib, numpy, scipy, threadpoolctl\n",
      "Required-by: mlflow\n"
     ]
    }
   ],
   "source": [
    "!pip show scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que tenemos esta información, la cual es muy importante, procederemos a crear un virutal environment para dar inicio a la creación de nuestro web deployment. \n",
    "\n",
    "#### **Paso 4**\n",
    "\n",
    "**USAR BASE ENVIRONMENT EN WINDOWS POWERSHELL**\n",
    "\n",
    "```bash\n",
    "pipenv install scikit-learn==1.3.0 flask\n",
    "```\n",
    "\n",
    "Ahora para entrar: \n",
    "\n",
    "```bash\n",
    "pipenv shell\n",
    "\n",
    "ls\n",
    "```\n",
    "Aparecen: \n",
    "\n",
    "* Pipfile\n",
    "\n",
    "* Pipfile.lock\n",
    "\n",
    "Vamos a explorar estos archivos.\n",
    "\n",
    "Aca se explican todas las dependencias de nuestro environment. \n",
    "\n",
    "#### **Paso 5**\n",
    "\n",
    "Procederemos a crear nuestros archivos para deployar a partir del script de la primera clase, estos archivos nos permitiran realizar un preprocesamiento de datos, cargar el modelo y realizar las predicciones. \n",
    "\n",
    "Comenzamos por el archivo **predict.py**:\n",
    "\n",
    "En primer lugar recuerda pegar el archivo .bin doonde guardaste el preprocesamiento y el modelo predictivo que entrenaste en la primera clase en el directorio en el que te encuetnras trabajando, estos son: \n",
    "\n",
    "* **lin_reg.bin**\n",
    "\n",
    "#### Versión inicial **predict_inicial.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Colocamos los inputs\n",
    "import pickle\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "# Abrimos el archivo donde estan las cosas que nos permitiran hacer predicciones\n",
    "with open('lin_reg.bin', 'rb') as f_in:\n",
    "    (dv, model) = pickle.load(f_in)\n",
    "\n",
    "def prepare_features(ride):\n",
    "    features = {}\n",
    "    features['PU_DO'] = '%s_%s' % (ride['PULocationID'], ride['DOLocationID'])\n",
    "    features['trip_distance'] = ride['trip_distance']\n",
    "    return features\n",
    "\n",
    "# Permite realizar las predicciones, hace el preprocesamiento y prediccion de los datos\n",
    "def predict(features):\n",
    "    X = dv.transform(features)\n",
    "    preds = model.predict(X)\n",
    "    return float(preds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguimos con el archivo **test_inicial.py** que nos permitira testear si nuestro codigo funciona correctamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos dentro de este script el script de predict_incial para poder utilizar sus funciones\n",
    "import predict_inicial\n",
    "\n",
    "ride = {\n",
    "    \"PULocationID\": 10,\n",
    "    \"DOLocationID\": 50,\n",
    "    \"trip_distance\": 40\n",
    "}\n",
    "\n",
    "features = predict_inicial.prepare_features(ride)\n",
    "pred = predict_inicial.predict(features)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chqueamos que obtengamos la prediccion de forma correcta con: \n",
    "\n",
    "```bash\n",
    "python .\\test_inicial.py\n",
    "```\n",
    "\n",
    "#### Ahora procedemos a implementar flask en los scripts anteriores: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Colocamos los inputs\n",
    "import pickle\n",
    "\n",
    "# Importamos tambien flask y las funciones necesarias\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "# Abrimos el archivo donde estan las cosas que nos permitiran hacer predicciones\n",
    "with open('lin_reg.bin', 'rb') as f_in:\n",
    "    (dv, model) = pickle.load(f_in)\n",
    "\n",
    "# Preparamos variables para la prediccion\n",
    "def prepare_features(ride):\n",
    "    features = {}\n",
    "    features['PU_DO'] = '%s_%s' % (ride['PULocationID'], ride['DOLocationID'])\n",
    "    features['trip_distance'] = ride['trip_distance']\n",
    "    return features\n",
    "\n",
    "# Permite realizar las predicciones, hace el preprocesamiento y prediccion de los datos\n",
    "def predict(features):\n",
    "    X = dv.transform(features)\n",
    "    preds = model.predict(X)\n",
    "    return float(preds[0])\n",
    "\n",
    "# Definimos nuestra app\n",
    "app = Flask('duration-prediction')\n",
    "\n",
    "# predict_endpoint es un wrapper que junta todo \n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict_endpoint():\n",
    "    # Recibimos el request y lo hacemos json\n",
    "    ride = request.get_json()\n",
    "\n",
    "    features = prepare_features(ride)\n",
    "    pred = predict(features)\n",
    "\n",
    "    result = {\n",
    "        'duration': pred\n",
    "    }\n",
    "\n",
    "    # Devolvemos resultado como json\n",
    "    return jsonify(result)\n",
    "\n",
    "# Esto es importante y necesario\n",
    "# Para cuadno ejecutemos desde consola valla al ip que reservamos para la app\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, host='0.0.0.0', port=9696)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguimos con el archivo **test.py** e introducimos leves modificaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "ride = {\n",
    "    \"PULocationID\": 10,\n",
    "    \"DOLocationID\": 50,\n",
    "    \"trip_distance\": 40\n",
    "}\n",
    "\n",
    "url = 'http://localhost:9696/predict'\n",
    "response = requests.post(url, json=ride)\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* si no lo hicimos antes recordar hacer: \n",
    "\n",
    "```bash\n",
    "pipenv install requests\n",
    "pipenv install gunicorn\n",
    "```\n",
    "\n",
    "#### Para ponerlo en funcionamiento\n",
    "\n",
    "* En primer lugar debemos dejar corriendo predict.py en el ip que definimos. \n",
    "\n",
    "```bash\n",
    "python .\\predict.py\n",
    "```\n",
    "\n",
    "Y desde otro terminal ejecutamos test.py\n",
    "\n",
    "```bash\n",
    "python .\\test.py\n",
    "```\n",
    "\n",
    "Esperamos a ver si funciona y continuamos. \n",
    "\n",
    "Ahora introduciremos todo dentro de un **Docker container**\n",
    "\n",
    "Chequeamos la version de python que estamos utilizando\n",
    "\n",
    "```bash\n",
    "python -V\n",
    "```\n",
    "\n",
    "Procedemos a crear el **Dockerfile**\n",
    "\n",
    "* En esta pagina podemos encontrar información con respecto a las imagenes de python para descargarlas [images](https://hub.docker.com/_/python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la imagen de python que vamos a utilizar\n",
    "FROM python:3.9.7-slim\n",
    "\n",
    "# Instalamos pip y pip env\n",
    "RUN pip install -U pip\n",
    "RUN pip install pipenv \n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Instalamos nuestras dependencias\n",
    "COPY [ \"Pipfile\", \"Pipfile.lock\", \"./\" ]\n",
    "\n",
    "RUN pipenv install --system --deploy\n",
    "\n",
    "# Copiamos los archivos necesarios para realizar las predicciones\n",
    "COPY [ \"predict.py\", \"lin_reg.bin\", \"./\" ]\n",
    "\n",
    "# Publicamos la docker image en el ip...\n",
    "EXPOSE 9696\n",
    "\n",
    "# Definimos el entrypoint, lo que va a ejecutar despues de que el container esta inciado\n",
    "ENTRYPOINT [ \"gunicorn\", \"--bind=0.0.0.0:9696\", \"predict:app\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que creamos todos estos archivos procedemos a ejecutar docker: \n",
    "\n",
    "**BUILD**:\n",
    "\n",
    "\n",
    "```bash\n",
    "docker build -t ride-duration-prediction-service:v1 .\n",
    "```\n",
    "\n",
    "(corre las instrucciones brindadas en dockerfile)\n",
    "\n",
    "Una vez que se construyo, hacemos el **RUN**.\n",
    "\n",
    "**RUN**:\n",
    "\n",
    "```bash\n",
    "docker run -it --rm -p 9696:9696  ride-duration-prediction-service:v1\n",
    "```\n",
    "\n",
    "(corremos la imagen construida)\n",
    "\n",
    "Cabe destacar que para poder correr estos comandos tendran que instalar docker desktop en sus computadoras. \n",
    "\n",
    "[Tutorial instalar DockerDesktop](https://docs.docker.com/desktop/install/windows-install/)\n",
    "\n",
    "Testeamos que este funcionando: \n",
    "\n",
    "```bash\n",
    "python .\\test.py\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
