{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ciencia de Datos e Inteligencia Artificial para la industria del software**\n",
    "\n",
    "# *Curso MLOps*\n",
    "\n",
    "## **Edición 2023**\n",
    "\n",
    "# 3. Orquestación\n",
    "\n",
    "## 3.1 Introducción a la Orquestación de Flujos de Trabajo\n",
    "\n",
    "Orquestar un flujo de trabajo de ML puede ser bastante desafiante. Hay muchos puntos potenciales de interrupción en el flujo, como indican las cruces rojas en la imagen:\n",
    "\n",
    "![Flujo Típico](https://stephen137.github.io/posts/MLOps_Zoomcamp_Module_3/ML_Ops_Zoomcamp_Module_3_files/figure-html/7985c817-ae3f-4b06-b7ad-c4a5be6efb81-2-5c4a30a6-4a39-4bd2-a17a-5533062dd67e.PNG)\n",
    "\n",
    "Afortunadamente, existen herramientas disponibles para solucionar estos problemas. Prefect proporciona un enfoque moderno, sólido y de fácil aplicación para la orquestación de flujos de trabajo, simplificando la gestión de *pipelines* de datos complejas y permitiendo una ejecución eficiente y confiable, así como el monitoreo y la visualización de los flujos de trabajo.\n",
    "\n",
    "A continuación se muestra una captura de pantalla de la interfaz de usuario de Prefect que ilustra cómo se podría orquestar un flujo típico:\n",
    "\n",
    "![Interfaz de Usuario de Prefect](https://stephen137.github.io/posts/MLOps_Zoomcamp_Module_3/ML_Ops_Zoomcamp_Module_3_files/figure-html/7985c817-ae3f-4b06-b7ad-c4a5be6efb81-1-2d954052-efcf-49dc-9214-2453d17ea473.PNG)\n",
    "\n",
    "## 3.2 Introducción a Prefect\n",
    "\n",
    "![Prefect](https://stephen137.github.io/posts/MLOps_Zoomcamp_Module_3/ML_Ops_Zoomcamp_Module_3_files/figure-html/cec5f8e8-85d2-4966-8e95-6a8af1e133a9-1-c372cec2-c169-43e5-bddc-af4cc2126188.PNG)\n",
    "\n",
    "Prefect es una herramienta de orquestación de flujos de trabajo que permite a los desarrolladores construir, observar y reaccionar ante *pipelines* de datos.\n",
    "\n",
    "Es la forma más sencilla de transformar cualquier función Python en una unidad de trabajo que puede ser observada y orquestada. Sólo tiene que incertar el código Python y colocar algunos decoradores.\n",
    "\n",
    "Prefect hace que sea fácil añadir reintentos automáticos, almacenamiento en caché y registro a tus funciones Python. Sólo tienes que decorar tu código con decoradores de flujo y tareas y estarás volando. 🛫\n",
    "\n",
    "Prefect permite automatizar procesos, su objetivo principal es facilitar la gestión y ejecución de flujos de trabajo complejos y distribuidos. \n",
    "\n",
    "#### Beneficios\n",
    "\n",
    "* Facilita la orquestación de flujos de trabajo complejos: Prefect permite **definir y gestionar flujos de trabajo** de manera programática utilizando código Python. Esto hace que sea más fácil representar y controlar flujos de trabajo complejos, donde las tareas deben ejecutarse en un orden específico o incluso en paralelo.\n",
    "\n",
    "* Control de flujo y manejo de errores: Con Prefect, puedes definir reglas de flujo y **manejo de errores de manera más eficiente**. Puedes especificar qué hacer **si una tarea falla, cómo reintentarla o cómo continuar con tareas alternativas en función de condiciones específicas**.\n",
    "\n",
    "* Programación distribuida: Prefect está diseñado para ejecutar flujos de trabajo distribuidos, lo que significa que puedes **aprovechar recursos de cómputo distribuidos**, como clústeres de máquinas o plataformas de contenedores, para ejecutar tareas en paralelo y de manera escalable.\n",
    "\n",
    "* Monitorización y seguimiento: Prefect proporciona herramientas para **monitorear y realizar un seguimiento detallado** de la ejecución de flujos de trabajo. Esto es valioso para el diagnóstico de problemas y la mejora de la eficiencia de los flujos de trabajo.\n",
    "\n",
    "* Flexibilidad y extensibilidad: Puedes **integrar Prefect con otras herramientas y servicios**, lo que lo hace altamente flexible y adecuado para su uso en diversos entornos y situaciones. También es extensible, lo que significa que puedes personalizar y ampliar su funcionalidad según tus necesidades específicas.\n",
    "\n",
    "* Reproducibilidad y versionamiento: Prefect promueve las mejores prácticas de **reproducibilidad y versionamiento** al permitirte definir flujos de trabajo como código, lo que facilita la reproducción de experimentos y el seguimiento de cambios en tus flujos de trabajo a lo largo del tiempo.\n",
    "\n",
    "En el contexto de MLOps, Prefect se utiliza comúnmente para orquestar flujos de trabajo relacionados con la preparación de datos, entrenamiento de modelos, evaluación de modelos, despliegue y monitorización. Su capacidad para gestionar flujos de trabajo complejos y distribuidos es especialmente útil en proyectos de Machine Learning donde se requiere coordinar múltiples etapas y recursos.\n",
    "\n",
    "#### Alternativas a Prefect\n",
    "\n",
    "* **Apache Airflow**: Es una de las herramientas más conocidas para orquestación de flujos de trabajo. Airflow permite definir flujos de trabajo como DAGs (Grafos Acíclicos Dirigidos) y ofrece una amplia gama de conectores y operadores para integrarse con diversas tecnologías y servicios.\n",
    "\n",
    "* **Luigi**: Desarrollado por Spotify, Luigi es otra herramienta de orquestación de flujos de trabajo. Al igual que Prefect, se utiliza para definir flujos de trabajo en Python y proporciona control de flujo y manejo de errores.\n",
    "\n",
    "* **Celery**: Aunque inicialmente se diseñó para la cola de tareas y la ejecución paralela en aplicaciones web, Celery se puede utilizar para orquestación de flujos de trabajo cuando se combina con otras bibliotecas y herramientas.\n",
    "\n",
    "* **Kubeflow Pipelines**: Si estás trabajando en un entorno de Kubernetes, Kubeflow Pipelines es una excelente opción. Está diseñado específicamente para la orquestación de flujos de trabajo en Kubernetes y es ampliamente utilizado en el contexto de la automatización de Machine Learning.\n",
    "\n",
    "* **AWS Step Functions**: Si estás en la nube de Amazon, AWS Step Functions es una opción para orquestar flujos de trabajo en AWS. Puedes utilizarlo para coordinar servicios y recursos de AWS en tus flujos de trabajo.\n",
    "\n",
    "* **Microsoft Azure Data Factory**: Si trabajas en el entorno de Azure, Azure Data Factory es una herramienta que te permite crear, programar y orquestar flujos de trabajo de datos en la nube.\n",
    "\n",
    "* **Google Cloud Composer**: Si utilizas Google Cloud, Cloud Composer es una plataforma gestionada que se basa en Apache Airflow y está diseñada para la orquestación de flujos de trabajo en Google Cloud.\n",
    "\n",
    "* **Rundeck**: Rundeck es una herramienta de orquestación de flujos de trabajo que se centra en la automatización de tareas operativas y la gestión de infraestructura.\n",
    "\n",
    "* **DAGsHub**: Una plataforma para gestionar flujos de trabajo de ML y Data Science que permite a los equipos colaborar en la orquestación y reproducción de flujos de trabajo.\n",
    "\n",
    "* **Tekton**: Si estás construyendo flujos de trabajo de CI/CD en entornos de contenedores, Tekton es una opción popular que se integra bien con Kubernetes.\n",
    "\n",
    "La elección de la herramienta dependerá de tus necesidades específicas, los servicios y tecnologías que utilices, y tus preferencias personales. Cada una de estas herramientas tiene sus propias características y ventajas, por lo que es importante evaluarlas en función de tus requerimientos y restricciones particulares.\n",
    "\n",
    "### 3.2.1 ¿Por qué usar Prefect?\n",
    "\n",
    "![Razones para Usar Prefect](https://stephen137.github.io/posts/MLOps_Zoomcamp_Module_3/ML_Ops_Zoomcamp_Module_3_files/figure-html/24f13b5a-1120-4a68-b62f-ce0ef243ea04-1-6f845297-335f-49cb-867c-c22357338b3b.PNG)\n",
    "\n",
    "* **Facilidad de uso:**\n",
    "Prefect proporciona una interfaz de usuario amigable y una API basada en Python, lo que facilita la definición y gestión de flujos de trabajo. Le permite escribir flujos de trabajo como código, aprovechando su conocimiento e infraestructura Python existente.\n",
    "\n",
    "* **Flexibilidad:**\n",
    "Prefect ofrece un marco flexible y extensible para definir flujos de trabajo. Admite dependencias complejas y le permite manejar flujos de trabajo dinámicos impulsados por datos. Puede crear, actualizar y versionar fácilmente sus flujos de trabajo a medida que evolucionan sus necesidades.\n",
    "\n",
    "* **Tolerancia a fallos:**\n",
    "Prefect proporciona tolerancia a fallos incorporada y mecanismos de reintento. Maneja las fallas de manera elegante al volver a intentar automáticamente las tareas fallidas y recuperarse de los errores. Puede configurar manejo de errores personalizados y notificaciones para garantizar que sus flujos de trabajo se ejecuten de manera confiable.\n",
    "\n",
    "* **Monitoreo y observabilidad:**\n",
    "Prefect ofrece características completas de monitoreo y observabilidad. Proporciona un panel basado en web donde puede visualizar y seguir el estado de sus flujos de trabajo, inspeccionar detalles a nivel de tarea y monitorear métricas de ejecución. Esto permite una fácil depuración, optimización de rendimiento y solución de problemas.\n",
    "\n",
    "* **Escalabilidad:**\n",
    "Prefect está diseñado para escalar horizontalmente, lo que le permite ejecutar flujos de trabajo en una infraestructura distribuida. Admite ejecución paralela y distribuida, lo que le permite ejecutar tareas de manera concurrente en múltiples máquinas o contenedores. Esto lo hace adecuado para el procesamiento de datos a gran escala y flujos de trabajo complejos.\n",
    "\n",
    "* **Integración y extensibilidad:**\n",
    "Prefect se integra perfectamente con varias tecnologías y servicios, como bases de datos, colas de mensajes, plataformas en la nube y más. Proporciona una amplia variedad de bibliotecas de tareas y le permite extender su funcionalidad mediante definiciones de tareas personalizadas y ganchos. Esto le permite integrar Prefect en su conjunto de tecnologías existente y aprovechar el poder de su ecosistema.\n",
    "\n",
    "* **Visibilidad y colaboración en flujos de trabajo:**\n",
    "Prefect promueve la colaboración y la visibilidad entre equipos. Ofrece características como control de versiones, compartición y edición colaborativa de flujos de trabajo. Puede compartir y reutilizar fácilmente flujos de trabajo en proyectos, lo que permite una mejor colaboración y compartición de conocimientos dentro de su organización.\n",
    "\n",
    "![Flujos de Trabajo en Prefect](https://stephen137.github.io/posts/MLOps_Zoomcamp_Module_3/ML_Ops_Zoomcamp_Module_3_files/figure-html/48700e8c-7f1e-4f4b-8653-84f1c6f446b3-1-598ca6c1-9e24-4144-a8c0-a5eeb2f364a6.PNG)\n",
    "\n",
    "![Flujo Principal y Subflujo en Prefect](https://stephen137.github.io/posts/MLOps_Zoomcamp_Module_3/ML_Ops_Zoomcamp_Module_3_files/figure-html/bae279ae-826a-4ff0-8d76-6ef536bda595-1-65cf645f-3220-4309-a291-897449294d68.PNG)\n",
    "\n",
    "![Ejemplo de Flujo en Prefect](https://stephen137.github.io/posts/MLOps_Zoomcamp_Module_3/ML_Ops_Zoomcamp_Module_3_files/figure-html/e340c1ac-f033-4ebf-ac57-c3109c692f49-1-953ecfb5-7726-457f-bdff-270d188d7b83.PNG)\n",
    "\n",
    "En el ejemplo anterior, tenemos un flujo principal llamado \"Hello Flow\" que llama al subflujo \"Subflow\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo introductio 1\n",
    "\n",
    "### a. Clonar el repositorio de Prefect en GitHub\n",
    "\n",
    "Para clonar el repositorio de Prefect, navegue hasta el directorio donde desea clonar y ejecute el siguiente comando desde la línea de comandos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'prefect-mlops-zoomcamp' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/discdiver/prefect-mlops-zoomcamp.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Configurar un entorno Conda\n",
    "\n",
    "Ahora, desde dentro de nuestro repo clonado, vamos a crear un entorno conda usando lo siguiente:\n",
    "\n",
    "```bash\n",
    "conda create -n prefect-ops python==3.9.12\n",
    "```\n",
    "y activamos el entorno usando :\n",
    "\n",
    "```bash\n",
    "conda activate prefect-ops\n",
    "```   \n",
    "Comprueba rápidamente que estamos utilizando la versión correcta de Python :\n",
    "\n",
    "```bash\n",
    "python -V\n",
    "```\n",
    "A continuación, pip install las dependencias incluidas en el archivo requirements.txt :\n",
    "\n",
    "```bash\n",
    "conda install pip\n",
    "```\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "Para ver el contenido del .txt, escribe en la terminal\n",
    "\n",
    "```bash\n",
    "cat requirements.txt\n",
    "```\n",
    "\n",
    "### c. Iniciar un servidor Prefect\n",
    "\n",
    "Podemos iniciar un servidor Prefect desde la línea de comandos:\n",
    "\n",
    "```bash\n",
    "prefect server start\n",
    "```\n",
    "\n",
    "Vamos a tomar la URL de la API y asegurarnos de que la aplicamos a nuestra configuración de Prefect para que estemos apuntando a la URL correcta de la API.\n",
    "\n",
    "Dentro de una nueva terminal, navega al mismo directorio que antes, activa el entorno conda y establece la URL de la API:\n",
    "\n",
    "```bash\n",
    "prefect config set PREFECT_API_URL=http://127.0.0.1:4200/api\n",
    "```\n",
    "\n",
    "Bien, ahora naveguemos a la carpeta 3.2 donde se encuentran los scripts que usaremos para ilustrar:\n",
    "\n",
    "```bash\n",
    "cat_facts.py\n",
    "```\n",
    "\n",
    "En caso de algun error: \n",
    "\n",
    "```bash\n",
    "pip install --upgrade pydantic prefect\n",
    "```\n",
    "\n",
    "A continuacion definiremos una "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">09:33:29.700 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - Created flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'unselfish-quetzal'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'fetch'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "09:33:29.700 | \u001b[36mINFO\u001b[0m    | prefect.engine - Created flow run\u001b[35m 'unselfish-quetzal'\u001b[0m for flow\u001b[1;35m 'fetch'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">09:33:29.708 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'unselfish-quetzal'</span> - View at <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:4200/flow-runs/flow-run/2450b3fc-9745-4f8e-a44a-1e7f8d37be41</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "09:33:29.708 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'unselfish-quetzal'\u001b[0m - View at \u001b[94mhttp://127.0.0.1:4200/flow-runs/flow-run/2450b3fc-9745-4f8e-a44a-1e7f8d37be41\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">09:33:29.834 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'unselfish-quetzal'</span> - Created task run 'fetch_cat_fact-0' for task 'fetch_cat_fact'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "09:33:29.834 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'unselfish-quetzal'\u001b[0m - Created task run 'fetch_cat_fact-0' for task 'fetch_cat_fact'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">09:33:29.836 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'unselfish-quetzal'</span> - Executing 'fetch_cat_fact-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "09:33:29.836 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'unselfish-quetzal'\u001b[0m - Executing 'fetch_cat_fact-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">09:33:33.550 | <span style=\"color: #d70000; text-decoration-color: #d70000\">ERROR</span>   | Task run 'fetch_cat_fact-0' - Encountered exception during execution:\n",
       "Traceback (most recent call last):\n",
       "  File \"c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\prefect\\engine.py\", line 1729, in orchestrate_task_run\n",
       "    result = await call.aresult()\n",
       "  File \"c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\prefect\\_internal\\concurrency\\calls.py\", line 291, in aresult\n",
       "    return await asyncio.wrap_future(self.future)\n",
       "  File \"c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\prefect\\_internal\\concurrency\\calls.py\", line 315, in _run_sync\n",
       "    result = self.fn(*self.args, **self.kwargs)\n",
       "  File \"C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_14544\\3890962043.py\", line 10, in fetch_cat_fact\n",
       "    raise Exception()\n",
       "Exception\n",
       "</pre>\n"
      ],
      "text/plain": [
       "09:33:33.550 | \u001b[38;5;160mERROR\u001b[0m   | Task run 'fetch_cat_fact-0' - Encountered exception during execution:\n",
       "Traceback (most recent call last):\n",
       "  File \"c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\prefect\\engine.py\", line 1729, in orchestrate_task_run\n",
       "    result = await call.aresult()\n",
       "  File \"c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\prefect\\_internal\\concurrency\\calls.py\", line 291, in aresult\n",
       "    return await asyncio.wrap_future(self.future)\n",
       "  File \"c:\\Users\\marti\\anaconda3\\envs\\mlops2023\\lib\\site-packages\\prefect\\_internal\\concurrency\\calls.py\", line 315, in _run_sync\n",
       "    result = self.fn(*self.args, **self.kwargs)\n",
       "  File \"C:\\Users\\marti\\AppData\\Local\\Temp\\ipykernel_14544\\3890962043.py\", line 10, in fetch_cat_fact\n",
       "    raise Exception()\n",
       "Exception\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">09:33:33.628 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'fetch_cat_fact-0' - Received non-final state 'AwaitingRetry' when proposing final state '<span style=\"color: #d70000; text-decoration-color: #d70000\">Failed</span>' and will attempt to run again...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "09:33:33.628 | \u001b[36mINFO\u001b[0m    | Task run 'fetch_cat_fact-0' - Received non-final state 'AwaitingRetry' when proposing final state '\u001b[38;5;160mFailed\u001b[0m' and will attempt to run again...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">09:33:34.591 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'fetch_cat_fact-0' - In the 1750s, Europeans introduced cats into the Americas to control pests.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "09:33:34.591 | \u001b[36mINFO\u001b[0m    | Task run 'fetch_cat_fact-0' - In the 1750s, Europeans introduced cats into the Americas to control pests.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">09:33:34.681 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'fetch_cat_fact-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "09:33:34.681 | \u001b[36mINFO\u001b[0m    | Task run 'fetch_cat_fact-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">09:33:34.756 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'unselfish-quetzal'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>('All states completed.')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "09:33:34.756 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'unselfish-quetzal'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m('All states completed.')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import httpx\n",
    "from prefect import flow, task\n",
    "\n",
    "\n",
    "@task(retries=4, retry_delay_seconds=0.1, log_prints=True) # decorator\n",
    "def fetch_cat_fact():\n",
    "    cat_fact = httpx.get(\"https://f3-vyx5c2hfpq-ue.a.run.app/\")\n",
    "    #An endpoint that is designed to fail sporadically\n",
    "    if cat_fact.status_code >= 400:\n",
    "        raise Exception()\n",
    "    print(cat_fact.text) # this will be logged\n",
    "\n",
    "\n",
    "@flow\n",
    "def fetch():\n",
    "    fetch_cat_fact()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fetch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código está utilizando la biblioteca Prefect para definir un flujo de trabajo simple que se encarga de realizar una solicitud HTTP a una página web y luego imprimir el contenido de la respuesta. A continuación la estructura y lo que está haciendo este código:\n",
    "\n",
    "1. Importaciones:\n",
    "   ```python\n",
    "   import httpx\n",
    "   from prefect import flow, task\n",
    "   ```\n",
    "   - `httpx` es una biblioteca que se utiliza para realizar solicitudes HTTP.\n",
    "   - `prefect` es la biblioteca de orquestación de flujos de trabajo que se está utilizando para definir el flujo de trabajo.\n",
    "\n",
    "2. Decorador `@task`:\n",
    "   ```python\n",
    "   @task(retries=4, retry_delay_seconds=0.1, log_prints=True)\n",
    "   ```\n",
    "   - Esto define una tarea llamada `fetch_cat_fact`. El decorador `@task` se utiliza para marcar esta función como una tarea que forma parte del flujo de trabajo Prefect.\n",
    "   - `retries=4` indica que esta tarea se volverá a intentar hasta 4 veces en caso de que falle.\n",
    "   - `retry_delay_seconds=0.1` establece un retraso de 0.1 segundos entre reintentos.\n",
    "   - `log_prints=True` permite que los mensajes de registro generados dentro de esta tarea se impriman en la salida estándar.\n",
    "\n",
    "3. Función `fetch_cat_fact()`:\n",
    "   ```python\n",
    "   def fetch_cat_fact():\n",
    "       cat_fact = httpx.get(\"https://f3-vyx5c2hfpq-ue.a.run.app/\")\n",
    "       if cat_fact.status_code >= 400:\n",
    "           raise Exception()\n",
    "       print(cat_fact.text)\n",
    "   ```\n",
    "   - Esta función realiza una solicitud HTTP a la URL \"https://f3-vyx5c2hfpq-ue.a.run.app/\" utilizando `httpx.get()`.\n",
    "   - Luego, verifica si el código de estado de la respuesta es mayor o igual a 400, lo que generalmente indica un error HTTP. Si es así, se lanza una excepción.\n",
    "   - Finalmente, imprime el contenido de la respuesta en la salida estándar.\n",
    "\n",
    "4. Función `fetch()`:\n",
    "   ```python\n",
    "   @flow\n",
    "   def fetch():\n",
    "       fetch_cat_fact()\n",
    "   ```\n",
    "   - Esta función `fetch()` se marca como un flujo de trabajo Prefect utilizando el decorador `@flow`.\n",
    "   - En este caso, el flujo de trabajo es bastante simple y consiste en llamar a la tarea `fetch_cat_fact()`.\n",
    "\n",
    "5. Ejecución del flujo de trabajo:\n",
    "   ```python\n",
    "   if __name__ == \"__main__\":\n",
    "       fetch()\n",
    "   ```\n",
    "   - Esta sección verifica si el script se está ejecutando como el programa principal (`__name__ == \"__main__\"`).\n",
    "   - Si es así, se inicia la ejecución del flujo de trabajo `fetch()`.\n",
    "\n",
    "En resumen, este código define un flujo de trabajo Prefect que realiza una solicitud HTTP a una URL y maneja posibles errores HTTP. La respuesta de la solicitud se imprime en la salida estándar. La estructura es típica de cómo se definen y ejecutan flujos de trabajo utilizando la biblioteca Prefect en Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función que llama a la API ha sido decorada con un decorador de tareas que ha sido configurado con los argumentos retries, retry_delay_seconds, y log_prints.\n",
    "\n",
    "Podemos ejecutar el flujo desde la línea de comandos utilizando:\n",
    "\n",
    "```bash\n",
    "python cat_facts.py\n",
    "```\n",
    "\n",
    "y seguir la ejecución en directo desde la UPI de Prefect.\n",
    "\n",
    "Como podemos ver, el flujo falló un par de veces, pero el argumento de reintentos incluido en el decorador funcionó. Y ya tenemos nuestro hecho del gato registrado:\n",
    "\n",
    "\"A diferencia de los perros, los gatos no han sufrido grandes cambios durante su proceso de domesticación\".\n",
    "\n",
    "**Ejecutemos ahora el otro script:**\n",
    "\n",
    "```bash\n",
    "python cat_dog_facts.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:59:23.057 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - Created flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'amorphous-mink'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'animal-facts'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:59:23.057 | \u001b[36mINFO\u001b[0m    | prefect.engine - Created flow run\u001b[35m 'amorphous-mink'\u001b[0m for flow\u001b[1;35m 'animal-facts'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:59:23.060 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'amorphous-mink'</span> - View at <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:4200/flow-runs/flow-run/fedff82c-8cba-4425-9a06-37bc0c37c8aa</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:59:23.060 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'amorphous-mink'\u001b[0m - View at \u001b[94mhttp://127.0.0.1:4200/flow-runs/flow-run/fedff82c-8cba-4425-9a06-37bc0c37c8aa\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:59:23.303 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'amorphous-mink'</span> - Created subflow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'amiable-harrier'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'fetch-cat-fact'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:59:23.303 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'amorphous-mink'\u001b[0m - Created subflow run\u001b[35m 'amiable-harrier'\u001b[0m for flow\u001b[1;35m 'fetch-cat-fact'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:59:23.305 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'amiable-harrier'</span> - View at <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:4200/flow-runs/flow-run/b1e85791-609b-42ca-b5d0-a6c87d0420ff</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:59:23.305 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'amiable-harrier'\u001b[0m - View at \u001b[94mhttp://127.0.0.1:4200/flow-runs/flow-run/b1e85791-609b-42ca-b5d0-a6c87d0420ff\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:59:24.633 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'amiable-harrier'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:59:24.633 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'amiable-harrier'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:59:24.771 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'amorphous-mink'</span> - Created subflow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'unyielding-chinchilla'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'fetch-dog-fact'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:59:24.771 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'amorphous-mink'\u001b[0m - Created subflow run\u001b[35m 'unyielding-chinchilla'\u001b[0m for flow\u001b[1;35m 'fetch-dog-fact'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:59:24.775 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'unyielding-chinchilla'</span> - View at <span style=\"color: #0000ff; text-decoration-color: #0000ff\">http://127.0.0.1:4200/flow-runs/flow-run/132334d3-dc0e-4379-95fa-ce19db9fc363</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:59:24.775 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'unyielding-chinchilla'\u001b[0m - View at \u001b[94mhttp://127.0.0.1:4200/flow-runs/flow-run/132334d3-dc0e-4379-95fa-ce19db9fc363\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:59:26.442 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'unyielding-chinchilla'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:59:26.442 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'unyielding-chinchilla'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:59:26.444 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'amorphous-mink'</span> - 🐱: Today there are about 100 distinct breeds of the domestic cat.\n",
       "🐶: While not the best when it comes to sight, dogs have a keen sense of hearing, and can hear sounds at 4 times the distance of humans.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:59:26.444 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'amorphous-mink'\u001b[0m - 🐱: Today there are about 100 distinct breeds of the domestic cat.\n",
       "🐶: While not the best when it comes to sight, dogs have a keen sense of hearing, and can hear sounds at 4 times the distance of humans.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">11:59:26.492 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'amorphous-mink'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>('All states completed.')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "11:59:26.492 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'amorphous-mink'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m('All states completed.')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import httpx\n",
    "from prefect import flow\n",
    "\n",
    "@flow\n",
    "def fetch_cat_fact():\n",
    "    '''A flow that gets a cat fact'''\n",
    "    return httpx.get(\"https://catfact.ninja/fact?max_length=140\").json()[\"fact\"]\n",
    "\n",
    "@flow\n",
    "def fetch_dog_fact():\n",
    "    '''A flow that gets a dog fact'''\n",
    "    return httpx.get(\n",
    "        \"https://dogapi.dog/api/v2/facts\",\n",
    "        headers={\"accept\": \"application/json\"},\n",
    "    ).json()[\"data\"][0][\"attributes\"][\"body\"] # index into the JSON file to retrieve the \"body\" - see below for example of JSON format\n",
    "\n",
    "@flow(log_prints=True)\n",
    "def animal_facts():\n",
    "    cat_fact = fetch_cat_fact()\n",
    "    dog_fact = fetch_dog_fact()\n",
    "    print(f\"🐱: {cat_fact} \\n🐶: {dog_fact}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    animal_facts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este script utiliza Subflows. El flujo principal `animal_facts` llama a `fetch_cat_fact` y luego a `fetch_dog_fact`. Ten en cuenta que debido a `log_prints=True`, la salida de los flujos se imprime y registra.\n",
    "\n",
    "🐱: En la versión original italiana de La Cenicienta, la figura benévola del hada madrina era un gato.\n",
    "\n",
    "🐶: La canción de The Beatles \"A Day in the Life\" tiene un silbido extra agudo, audible solo para los perros. Fue grabado por Paul McCartney para el disfrute de su perro pastor de Shetland.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Flujo de Trabajo de Prefect\n",
    "\n",
    "### 3.3.1 Predicción ride duration trip (Notebook del Módulo 2)\n",
    "\n",
    "En la primera clase construimos un modelo simple de predicción de duración de viaje en taxi en la ciudad de Nueva York. El código fue compilado deliberadamente en un cuaderno Jupyter, el cual involucra el proceso de pensamiento y los pasos generales involucrados en la exploración y preprocesamiento de datos crudos para el entrenamiento de aprendizaje automático. Si bien un cuaderno Jupyter es adecuado para la experimentación interna, cuando se trata de producción/despliegue, quizás necesitamos algo más robusto y escalable.\n",
    "\n",
    "Cuando el código está disperso en un cuaderno Jupyter, las cosas pueden volverse rápidamente desordenadas, especialmente cuando comienzas a iterar sobre diferentes modelos y parámetros. Puede haber una sensación de que estás perdiendo el control sobre tu experimento. Un primer paso hacia la mejora es unificar todo en un solo script de Python.\n",
    "\n",
    "### 3.3.2 Predicción de la duración del viaje en un script de Python\n",
    "\n",
    "Un primer paso hacia la mejora es unificar todo en un solo script de Python:\n",
    "\n",
    "`orchestrate_pre_prefect.py`\n",
    "\n",
    "Este script unifica todos los procedimientos necesarios para entrenar el modelo de aprendizaje automatico desarrollado preivamente.\n",
    "\n",
    "   ```python\n",
    "import pathlib\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import mlflow\n",
    "import xgboost as xgb\n",
    "from prefect import flow, task\n",
    "\n",
    "\n",
    "def read_data(filename: str) -> pd.DataFrame:\n",
    "    \"\"\"Read data into DataFrame\"\"\"\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "    df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "\n",
    "    df[\"duration\"] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = [\"PULocationID\", \"DOLocationID\"]\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_features(\n",
    "    df_train: pd.DataFrame, df_val: pd.DataFrame\n",
    ") -> tuple(\n",
    "    [\n",
    "        scipy.sparse._csr.csr_matrix,\n",
    "        scipy.sparse._csr.csr_matrix,\n",
    "        np.ndarray,\n",
    "        np.ndarray,\n",
    "        sklearn.feature_extraction.DictVectorizer,\n",
    "    ]\n",
    "):\n",
    "    \"\"\"Add features to the model\"\"\"\n",
    "    df_train[\"PU_DO\"] = df_train[\"PULocationID\"] + \"_\" + df_train[\"DOLocationID\"]\n",
    "    df_val[\"PU_DO\"] = df_val[\"PULocationID\"] + \"_\" + df_val[\"DOLocationID\"]\n",
    "\n",
    "    categorical = [\"PU_DO\"]  #'PULocationID', 'DOLocationID']\n",
    "    numerical = [\"trip_distance\"]\n",
    "\n",
    "    dv = DictVectorizer()\n",
    "\n",
    "    train_dicts = df_train[categorical + numerical].to_dict(orient=\"records\")\n",
    "    X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "    val_dicts = df_val[categorical + numerical].to_dict(orient=\"records\")\n",
    "    X_val = dv.transform(val_dicts)\n",
    "\n",
    "    y_train = df_train[\"duration\"].values\n",
    "    y_val = df_val[\"duration\"].values\n",
    "    return X_train, X_val, y_train, y_val, dv\n",
    "\n",
    "\n",
    "def train_best_model(\n",
    "    X_train: scipy.sparse._csr.csr_matrix,\n",
    "    X_val: scipy.sparse._csr.csr_matrix,\n",
    "    y_train: np.ndarray,\n",
    "    y_val: np.ndarray,\n",
    "    dv: sklearn.feature_extraction.DictVectorizer,\n",
    ") -> None:\n",
    "    \"\"\"train a model with best hyperparams and write everything out\"\"\"\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        train = xgb.DMatrix(X_train, label=y_train)\n",
    "        valid = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "        best_params = {\n",
    "        'learning_rate': 0.4434065752589766,\n",
    "        'max_depth': 81,\n",
    "        'min_child_weight': 10.423237853746643,\n",
    "        'objective': 'reg:linear',\n",
    "        'reg_alpha': 0.2630756846813668,\n",
    "        'reg_lambda': 0.1220536223877784,\n",
    "        'seed': 42    \n",
    "        }\n",
    "\n",
    "        mlflow.log_params(best_params)\n",
    "\n",
    "        booster = xgb.train(\n",
    "            params=best_params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=3,\n",
    "            evals=[(valid, \"validation\")],\n",
    "            early_stopping_rounds=3,\n",
    "        )\n",
    "\n",
    "        y_pred = booster.predict(valid)\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        pathlib.Path(\"models\").mkdir(exist_ok=True)\n",
    "        with open(\"models/preprocessor.b\", \"wb\") as f_out:\n",
    "            pickle.dump(dv, f_out)\n",
    "        mlflow.log_artifact(\"models/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "\n",
    "        mlflow.xgboost.log_model(booster, artifact_path=\"models_mlflow\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def main_flow(\n",
    "    train_path: str = \"./data/yellow_tripdata_2022-01.parquet\",\n",
    "    val_path: str = \"./data/yellow_tripdata_2022-02.parquet\",\n",
    ") -> None:\n",
    "    \"\"\"The main training pipeline\"\"\"\n",
    "\n",
    "    # MLflow settings\n",
    "    mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "    mlflow.set_experiment(\"nyc-taxi-experiment\")\n",
    "\n",
    "    # Load\n",
    "    df_train = read_data(train_path)\n",
    "    df_val = read_data(val_path)\n",
    "\n",
    "    # Transform\n",
    "    X_train, X_val, y_train, y_val, dv = add_features(df_train, df_val)\n",
    "\n",
    "    # Train\n",
    "    train_best_model(X_train, X_val, y_train, y_val, dv)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_flow()\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, navega al directorio (3.3) donde se encuentra `orchestrate_pre_prefect.py` y ejecuta desde la línea de comandos:\n",
    "\n",
    "```bash\n",
    "python orchestrate_pre_prefect.py\n",
    "```\n",
    "\n",
    "* *Si hay algun error borrar la DB de Mlflow* (alembic)\n",
    "\n",
    "Podemos agregar más refinamiento utilizando Prefect. Veamos esto en acción.\n",
    "\n",
    "### 3.3.2 Aprovechando Prefect para mejorar el script (**orquestación**)\n",
    "\n",
    "Podemos continuar construyendo sobre el script de Python agregando tareas y decoradores de flujo:\n",
    "\n",
    "`orchestrate.py`\n",
    "\n",
    "Explicación codigo: \n",
    "\n",
    "```python\n",
    "import pathlib\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import mlflow\n",
    "import xgboost as xgb\n",
    "from prefect import flow, task\n",
    "```\n",
    "\n",
    "En esta parte, se realizan importaciones de bibliotecas y módulos necesarios para el flujo de trabajo. `prefect` se importa junto con otras bibliotecas de Python que se utilizarán más adelante.\n",
    "\n",
    "```python\n",
    "@task(retries=3, retry_delay_seconds=2)\n",
    "def read_data(filename: str) -> pd.DataFrame:\n",
    "    \"\"\"Read data into DataFrame\"\"\"\n",
    "    # ... (Carga y procesamiento de datos) ...\n",
    "    return df\n",
    "```\n",
    "\n",
    "- `@task` es un decorador que marca la función `read_data` como una tarea Prefect. Esta tarea carga un archivo de datos en formato parquet, realiza varias transformaciones en el DataFrame y devuelve el DataFrame procesado. También tiene configuración de reintentos en caso de fallo.\n",
    "\n",
    "```python\n",
    "@task\n",
    "def add_features(\n",
    "    df_train: pd.DataFrame, df_val: pd.DataFrame\n",
    ") -> tuple(\n",
    "    [\n",
    "        scipy.sparse._csr.csr_matrix,\n",
    "        scipy.sparse._csr.csr_matrix,\n",
    "        np.ndarray,\n",
    "        np.ndarray,\n",
    "        sklearn.feature_extraction.DictVectorizer,\n",
    "    ]\n",
    "):\n",
    "    \"\"\"Add features to the model\"\"\"\n",
    "    # ... (Agrega características al conjunto de datos y realiza la vectorización de características) ...\n",
    "    return X_train, X_val, y_train, y_val, dv\n",
    "```\n",
    "\n",
    "- La función `add_features` es otra tarea Prefect que agrega características al conjunto de datos y utiliza `DictVectorizer` para transformar características categóricas en una representación numérica. Devuelve varias matrices y objetos relacionados.\n",
    "\n",
    "```python\n",
    "@task(log_prints=True)\n",
    "def train_best_model(\n",
    "    X_train: scipy.sparse._csr.csr_matrix,\n",
    "    X_val: scipy.sparse._csr.csr_matrix,\n",
    "    y_train: np.ndarray,\n",
    "    y_val: np.ndarray,\n",
    "    dv: sklearn.feature_extraction.DictVectorizer,\n",
    ") -> None:\n",
    "    \"\"\"train a model with best hyperparams and write everything out\"\"\"\n",
    "    # ... (Entrenamiento de un modelo XGBoost, registro de parámetros y métricas con MLflow) ...\n",
    "    return None\n",
    "```\n",
    "\n",
    "- `train_best_model` es la tercera tarea Prefect en el flujo de trabajo. Entrena un modelo XGBoost con hiperparámetros específicos, registra los parámetros y métricas de rendimiento con MLflow, y guarda el modelo entrenado y otros artefactos en el sistema de archivos.\n",
    "\n",
    "```python\n",
    "@flow\n",
    "def main_flow(\n",
    "    train_path: str = \"./data/yellow_tripdata_2022-01.parquet\",\n",
    "    val_path: str = \"./data/yellow_tripdata_2022-02.parquet\",\n",
    ") -> None:\n",
    "    \"\"\"The main training pipeline\"\"\"\n",
    "    # ... (Configuración de MLflow, carga de datos, transformación de características y entrenamiento de modelo) ...\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_flow()\n",
    "```\n",
    "\n",
    "- `main_flow` es la función que define el flujo de trabajo principal. Configura MLflow, carga datos de archivos parquet, realiza transformaciones de características y entrena un modelo utilizando las tareas Prefect definidas anteriormente.\n",
    "\n",
    "- La sección final verifica si el script se está ejecutando como el programa principal (`if __name__ == \"__main__\"`) y, si es así, ejecuta el flujo de trabajo principal llamando a `main_flow()`.\n",
    "\n",
    "En resumen, este código utiliza Prefect para definir un flujo de trabajo que incluye tareas para cargar y procesar datos, transformar características y entrenar un modelo de aprendizaje automático. Prefect permite organizar y ejecutar estas tareas de manera eficiente, facilitando la automatización y el seguimiento de todo el proceso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero navegue hasta el directorio donde se encuentra orchestrate.py y ejecute desde la línea de comandos :\n",
    "\n",
    "```bash\n",
    "python orchestrate.py\n",
    "```\n",
    "Y podemos visualizar la ejecución usando el Prefect UI.\n",
    "\n",
    "* Si llegase a ocurrir un error borrar **mlflow.db**\n",
    "\n",
    "Una vez ejecutado explorar la corrida en la API. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
